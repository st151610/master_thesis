How does action change an outcome?
How should I guide my actions towards a better outcome?
The first question is about causality, the second about ethics.

How do causality and ethics reflect on statistics?
If you have not spent much time thinking about study design, this is a good way to start: 
As an analyst, ask yourself “Who acted? Who assigned treatment?"
As researcher -- plan your study accurately. You can ask yourself “How do we act? How do we assign treatment? Can we act?"

Let's say, you gather a sample from a study population, assign treatment (but forget how you did it). Some units get the drug, others don't. Then the statistical analysis shows a strong correlation of treatment and outcome. You hurry to your supervisor. “How was treatment assigned", asks she. “I forgot", says you.
“How do you know your analysis is correct then?"
You show her the data and together find out, that all units that received treatment were significantly taller than the rest of the sample.
After all, is the drug or the height responsible for the change  in outcome?
You realise, that the data is worthless for answering this question.
But you are lucky: It is just grass and fertiliser you were studying.

You get a second chance. A new medication needs testing before it enters the market. 
A company shall recruit participants, but the board requires you to write an outline for the study.
You carefully  explain steps to minimize risks for participants. You include plans to meet other requirements of human research.
Then you have to decide how to assign treatment.
No hand waving this time. You talk to your supervisor.
“Last time, too many tall grass blades received fertiliser. The distribution of treatment was not really random..."
You decide to determine treatment status by the flip of a fair coin.
You call the procedure 'randomization'.

%Randomization does not work in important situations. 
Would you smoke if a coin tells you to? If you say yes - you likely smoke anyway. The point is that forcing someone to smoke is unethical. But so is not studying the risks of smoking.

A professor is curious if the smoking habits of his students affect their grades. 
He observes the smoking area through his field glasses.
His assistant gets to know his plans. He warns him. “Many students attend parties the night before exams. Maybe they are also more likely to smoke." “I shall see this for myself..." says the professor. He puts away the field glasses. After a while, he visits the local club.
He talks to a few of his students. Some smoke, some don't. The chats are enjoyable. He thinks: “Some of my best students celebrate before the exams."


I hope, by now it's clear that 
we should focus on treatment assignment.
The propensity score\cite{Rosenbaum1983}, that is,
the probability of treatment given (observed) individual characteristics,
helps with that.
\begin{theorem*}
  \emph{\cite[Theorem~1]{Rosenbaum1983}}
Observed individual characteristics are independent 
of treatment assignment given the propensity score.
\end{theorem*}



In the second example, where you flip a fair coin to assign treatment, the propensity score is $1/2$, despite variation across individual characteristics.
The coin ignores everything.
What is the propensity score in the other examples?
I admit, I don't know.
It varies, but we can see trends. 
In the first example, tall grass blades had a large propensity score.
In the third example, the assistant thinks that students attending parties have a larger propensity score. This is not true, after all, but somehow the best students have a large propensity to celebrate before exams. 

The propensity score is a simple concept that works well with potential outcomes.
They are potential, because they exist (or we assume they exist) independent of our observation. They live in parallel universes.
If we have a binary treatment, that is, you either treat or don't, there are two potential outcomes. One under treatment and one under no treatment.
Ideally we would like to compare (for one unit) those two potential outcomes.
But that is impossible. 
Instead people keep asking:
“Had it been better if (20 years ago) I made a different decision?"
You know what happened but don't know what would have happened.
On a high-level: If you act, you can't observe at the same time the effect of no action.
Thus one of the potential outcomes always remains potential.
Of course there are tricks. You can  wait for the effect of an action to vanish and then observe the outcome (under similar conditions) again.
This works well when the effect of an action is short term.

If the propensity score is known we actually observe one of the potential outcomes.
This is because treatment assignment carries no more information \emph{\cite[Theorem~1]{Rosenbaum1983}}.
But we saw that assignment often carries more information, especially if the assignment mechanism is unknown.
This is typical for observational studies.
Somehow grass blades that received fertiliser were also taller.
Or students attending parties before the exams had better results.
It is not clear, if the effect on the outcome stems from observed or unobserved individual characteristics or the received treatment.
Then we observe neither of the two potential outcomes, but a biased version.
Why then bother?

Since the introduction of the propensity score in 1983 \cite{Rosenbaum1983}, statisticians developed different ideas how to incorporate it in their analysis. 
%
There are two important branches of application - matching and weighting.
In matching the idea is to pair two or more units with different treatment status but similar propensity score and compare their outcome. 
The assumption is that the propensity score eliminates imbalances and makes the paired units comparable.
In weighting - the method we will focus on - the idea is to re-weight the population, ideally with the inverse propensity score, that is, 1 divided by the propensity score.
Both methods share the goal to minimize imbalances in the population
and make the two groups, that is, treatment and control (no treatment) group more comparable.
Let's introduce some notation to be more precise.

Let $T\in \left\{ 0,1 \right\}$ be the \textbf{indicator of treatment}. 
Let $X\in\mathcal{X}$ be a vector with individual characteristics. We call this the \textbf{covariate vector}. 

Furthermore, let $(Y(0),Y(1))$ be the \textbf{potential outcomes}, that is, $Y(0)$ is the potential outcome under no treatment and $Y(1)$ the potential outcome under treatment.
All the quantities we introduce are random variables.

We define the propensity score $\pi$ with individual characteristics $x\in\mathcal{X}$ to be
\begin{gather*}
\pi(x)
\ 
:=
\ 
\P[T=1|X=x]
\end{gather*}
We observe  
\begin{gather*}
  \text{either}
  \qquad
  Y(0)\,|\,T=0
  \qquad
  \text{or}\qquad
  Y(1)\,|\,T=1
  \,.
\end{gather*}
We show in Lemma~\ref{ps_weights_lemma}, that if treatment assignment is \textbf{strongly ignorable}\cite[(1.3)]{Rosenbaum1983}
\begin{gather*}
  (Y(0),Y(1))\ \perp \ T \,|\,X
  \quad
  \text{and}
  \quad
  0<\pi(X)<1
  \,,
\end{gather*}
that is, 
potential outcomes are independent of treatment given covariates and every possible set of characteristic has a chance to receive treatment,
we get 
\begin{gather}
  \label{ipw}
  \E
  \left[ 
    \frac{T}{\pi(X)}Y(T)
  \right]
  =
  \E
  \left[ Y(1) \right]
  \,.
\end{gather}
That is, by weighting the observed outcome under treatment with the inverse propensity score we recover (in expectation) the potential outcome under treatment. 
This is relevant, because 
$Y(t)|T=t$ does not have the same distribution as $Y(t)$ for $t\in \left\{ 0,1 \right\}$.

In observational studies - independent of which method is applied, that is, matching, weighting ore other methods -
the propensity score is unknown.
This is because we can't assign treatment. We only observe the treated or untreated. Who assigned treatment is a philosophical question - at least to some extent.

It used to be very popular to use estimates of the propensity score - either for matching or to create weights or for some other purpose.
In weighting, the hope is to recover \eqref{ipw} from the estimate.
In practice, however, estimating the propensity score is a difficult task.
Researchers often compare estimates from different models and check for covariate balance. 
This is not surprising, because that's what the weights are designed for - minimizing imbalances in the population.
The poor performance of classical propensity score estimates such as logistic regression - and the insight that the task is to eliminate imbalances -
led to the development of methods such as the Covariate Balancing Propensity Score \cite{Imai2014a} that tries to 
estimate the propensity score and balance covariates simultaneously (the name is indicative).

Recently, new balancing frameworks were developed that do not rely on estimates of the propensity score\cite{Hainmueller2012,Zubizarreta2015}.
They generate weights with a constrained convex optimization problem that explicitly bounds imbalances by the constraints. 
The constraints responsible are of the form
\begin{gather}
  \label{cov_bal}
    \sum_{i=1}^{N}
    T_i
    \cdot
    w_i
    \cdot
    B_k(X_i)
    \ 
  =
    \ 
    \sum_{i=1}^{N} 
    B_k(X_i)
  \qquad
  \text{for all}\ 
  k\,,
\end{gather}
where $B_k$ are basis functions of the covariates.
The aim is to balance the weighted group (here the treatment group) against the whole sample.
The basis functions can be moments of the covariates - a natural aim. 
But it is a non-trivial question, which basis to choose in practice to obtain best performance.
How strictly to enforce covariate balance is another question.
It is relevant, because very strict assumptions can render the problem infeasible, whereas loosening can result in bias of the estimator.
In \cite{Hainmueller2012} the authors choose the (known) moments of the covariate as basis functions and enforce strict balance, that is, \eqref{cov_bal}.
In \cite{Wang2019} they consider the regression basis of sieve estimators\cite{Newey1997a}, where the number of basis functions grows with the sample size.
Also they loosen the strict constraints on the covariate balance as to vanish only for $N\to\infty$, that is,
\begin{gather*}
  \left| 
  \frac{1}{N}
  \left( 
    \sum_{i=1}^{n}
    w_i
    B_k(X_i)
    -
    \sum_{i=1}^{N} 
    B_k(X_i)
  \right)
  \right|
  \le
  \delta_k
  \qquad
  \text{for all}\ 
  k\,,
\end{gather*}
with $\delta_k > 0 $ and $\delta_k\to 0$ for $N\to\infty$.

What attracted my attention was that
the paper \cite{Wang2019} also contains theoretical analysis.
The authors reveal a surprising connection to propensity score estimation.
They show that with the regression basis of sieve estimators\cite{Newey1997a}, their method (implicitly) models the inverse propensity score.
They use this to obtain asymptotic normality of a weighted mean estimate of the expectation of potential outcomes.

One novelty introduced in this thesis is to balance basis functions of partitioning estimates \cite[§4]{Gyorfi2002}.
I show that this makes the proofs of \cite{Wang2019} easier.
Furthermore, I extend the framework to estimate the distribution function of potential outcomes.

I show, that (under mild assumptions) with the regression basis of partitioning estimates, the weighted mean is asymptotically well behaved in estimating distribution functions.
By the functional delta method
\cite[§20]{Vaart2000} results of this thesis immediately open access to a large class of plug-in estimators.
Therefore,
with this thesis I contribute to one of the main purposes in causal inference -- reinforcing classical methods of statistical analysis for use in observational studies.



%You sit in a plain room. There are two chairs. You sit in one of them.
%A person enters the room. “Subject 3225057? The coin decided. You have to smoke!"
%On your way out, anguished cries hit you from another room.
%“Please! Don't make me smoke!"
%You feel mild anxiety and wake up. It was just a dream. But it recurs. You talk to a friend. “I dream about a randomized study about the effects of smoking. A cold, indifferent coin decides who smokes. The non-smokers suffer a lot." When you realise, that this is all non-sense, you feel silly. But your friend
%But you happen to be a professor at the university.
%One day, in your office, you lean out of the window.“Give me the field glasses please. I want to observe my students smoking in the backyard."“What for?" asks your assistant. “Let's see, if this affects their grades" you murmur and look through the eyepieces. The issue comes up again at lunch. “Did you consider that some of the students that smoke also go to a party the night before an exam."“Well, maybe I should. How about I see for myself?" The night before the next exam, you openly enter the place of the party. You find some of the students you deem smartest at the bar. You're having a conversation. But it's to loud in there and in the morning you have an headache.
%
%
%%randomized trials versus observational studies
%
%Is study design more important then statistical analysis?
%
%I think, they are at least equal. 
%
%But a bad analysis can be undone,
%whereas a bad design can not.
%
%You have to stick with the data.
%
%If you are not familiar with study design the distinction between randomized and observational study is helpful.
%
%If you read the literature and are unsure about the design of a study, ask for this terms.
%
%You are likely to find an answer.
%
%
%It is all about how we collect the data.
%
%Say, we want to test the effect of a drug in a study population.
%
%There usually are differences among the units of the study population.
%
%Some are more healthy than others.
%
%We form a treatment and control group, that is, one group takes the drug and the other doesn't.
%
%Then we compare the groups by their health. 
%
%Then a critcal review comes in. What do you mean by healthy.
%
%We mean this and that.
%
%It seems you did not consider this factor.
%
%Maybe the drug is not effective, but the effect we see in your analysis comes from something else.
%
%What do we answer to this?
%
%
%A good method to avoid this awkward situation is to randomize.
%
%For every unit of the population we toss a fair coin that decides if they get the drug.
%
%Now comes the critic.
%
%From the tables it seems there is an effect. But what about unknown influence?
%
%We answer: Does the coin now of them?
%
%It is not ideal, but this way you can prevent systematic damage to your analysis.
%
%
%What if we can't decide who gets treatment?
%
%Don't think treatment has to be something good, it should not carry any label of good or bad.
%
%But what about smoking?
%
%Would you smoke if a coin tells you to?
%
%So this is unethical.
%
%But it is also unethical not to investigate the effects of smoking on the health.
%
%Let's accept, that we sometimes (often?) can not control who gets treatment.
%
%Some smoke, some don't, and we mearly observe.
%
%This is typical example for an observational study.
%
%Honestly, this is an oversimplification, but I hope you get the point.
%
%Who still is insulted by the tone will maybe like\cite{Rubin2007}.
%
%%propensity score
%
%In \cite{Rubin2007} you will find the propensity score.
%
%The propensity score is the individual probability to receive treatment, that is,
%\begin{gather}
%  \P
%  [T=1|X]
%\end{gather}
%if $T$ is the random variable that decides abuot treatment and $X$ is the vector that carries your individual information.
%
%This concept goes back to \cite{Rosenbaum1983}.
%
%It is maybe worth to stop here and think about this definition and its connection to the two study designs.
%
%Discover it for yourself.
%
%\begin{reflection*}
%What is the propensity score in the above example.
%How does the propensity score behave in rs and os?
%\end{reflection*}
%
%
%
%
%
%
