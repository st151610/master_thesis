Excursively, we present some well known definitions and facts from
convex analysis. For details, see, e.g., \cite{Mordukhovich2022}.

A subset $C\subseteq \R^n$ is called \textbf{convex set}, 
if for all $x,y\in C$ and all $\lambda\in [0,1]$,
we have 
$
  \lambda x + (1-\lambda)y 
  \in
  C
  .
$
The Cartesian product of convex sets is convex. The intersection of a collection of convex sets is also convex.




Given (not necessary convex) sets 
$
  \Omega,
  \Omega_1,
  \Omega_2
  \subseteq 
  \R^n
$
and
$\lambda\in\R,$
define the \textbf{set addition} and \textbf{multiplication}
by a real scalar as 
$
  \Omega_1 
  +
  \Omega_2 
  :=
  \left\{ 
    x_1 + x_2 
    \colon
    x_1 \in \Omega_1
    ,
    x_2 \in \Omega_2
  \right\}
$
and
$
  \lambda \Omega
  :=
  \left\{ 
    \lambda x
    \colon
    x\in\Omega
  \right\}.
$
For convex sets the addition and multiplication by a real scalar are convex.

Throughout this section, we shall denote by 
$
  B
  :=
  \left\{ 
    x=
    [x_1, \ldots, x_n]^\top
    \in\R^n
    \colon
    (
    \sum_{i=1}^{n} 
    x_i^2
    )
    ^{1/2}
    \le 1
  \right\}
$
\todo[color=green!40,inline]{Solve editorial issue with ball.}
the \textbf{Euclidian unit ball} in $\R^n.$
This is a closed convex set. For any $a\in\R^n,$ 
the \textbf{ball with radius $\varepsilon >0$ and center $a$}
is given by
$
  \left\{ 
   a+x 
    \in\R^n
    \colon
    (
    \sum_{i=1}^{n} 
    x_i^2
    )
    ^{1/2}
    \le \varepsilon
  \right\}
  =
  a
  +
  \varepsilon B
  .
$
For any set $\Omega$ in $\R^n,$ 
the set of points $x$ whose distance from $\Omega$
does not exceed $\varepsilon$ is 
$
\Omega + \varepsilon B.
$
The \textbf{closure} $\mathrm{cl}(\Omega)$
and \textbf{interior} $\mathrm{int}(\Omega)$
of $\Omega$
can therefore be expressed by 
$
  \mathrm{cl}(\Omega)
  =
  \bigcap_{\varepsilon>0}
  \Omega + \varepsilon B
$
and
$
  \mathrm{int}(\Omega)
  =
  \left\{ 
    x\in \Omega
    \colon
    \text{there exists $\varepsilon>0$ such that }
    x+\varepsilon B
    \subseteq
    \Omega
  \right\}
  .
$

  A set 
  $A\subseteq \R^n$
  is called \textbf{affine set}, if
  $
    \alpha x + (1-\alpha)y \in A
    \quad
    \text{for all}
    \ 
    x,y \in A
    \ 
    \text{and}
    \ 
    \alpha \in \R.
  $
  The \textbf{affine hull} 
  $\mathrm{aff}(\Omega)$
  of a set 
  $\Omega\subseteq \R^n$
  is the smallest affine set that includes $\Omega.$
A mapping 
$
  A: \R^n \to \R^m
$
is called \textbf{affine mapping} if there exist a linear mapping
$
  L: \R^n \to \R^m
$
and a vector $b\in \R^m$
such that
$
  A(x)
  =
  L(x)
  +
  b
  \ 
  \text{for all}\ 
  x \in \R^n
  .
$
The image and inverse image/preimage of convex sets under affine mappings are also convex.





Because the notion of interior is not precise enough for our purposes
we define the relative interior which is the interior relative to the affine hull.
This concept is motivated by the fact that a line segment embedded in $\R^2$
does have a natural interior in $\R$ which is not a true interior in $\R^2.$
The relative interior of $C$ is defined as the interior which results when
$C$ is regarded as a subset of its affine hull.
\begin{definition}
  Let 
  $\Omega\subseteq \R^n.$
  We define the \textbf{relative interior} of $\Omega$ by
  \begin{gather}
    \mathrm{ri}(\Omega)
    :=
    \left\{ 
      x \in \Omega 
      \colon
      \text{there exists}\ 
      \varepsilon > 0\ 
      \text{such that}\ 
      (
        x+\varepsilon B
      )
      \cap
      \mathrm{aff}(\Omega)
      \subset
      \Omega
    \right\}.
  \end{gather}
\end{definition}
Next we collect some useful properties of relative interiors.
\begin{proposition}
  \label{cv:primer:prop}
  Let $C$ be a non-empty convex set in $\R^n.$ The following holds:
\begin{enumerate}[label={(\roman*)}]
  \item
    $
      \mathrm{ri}(C)
      \ 
      \neq
      \ 
      \emptyset
      $
if and only if
      $
      C
      \ 
      \neq
      \ 
      \emptyset
    $
  \item
    The sets
    $
      \mathrm{cl}\,C
      $
      and
      $
      \mathrm{ri}\,C
    $
    are convex
  \item
    $
      \mathrm{cl}(\mathrm{ri}\,C)
      \ 
      =
      \ 
      \mathrm{cl}\,C
      $
      and
      $
      \mathrm{ri}(\mathrm{cl}\,C)
      \ 
      =
      \ 
      \mathrm{ri}(C)
    $
  \item
    $
    \mathrm{ri}(C)
      \ 
    =
      \ 
    \left\{ 
      z \in C
      \colon
      \text{for all}\ 
      x \in C \ 
      \text{there exists}\ 
      t > 0 \ 
      \text{such that}\ 
      z + t (z-x)
      \in C
    \right\}
    $
  \item
    Suppose
    $
      \bigcap_{i\in I} C_i
      \ 
      \neq
      \ 
      \emptyset
    $
    for a finite index set $I$.
    Then
    $
      \mathrm{ri}
      \left( 
        \bigcap_{i\in I} C_i
      \right)
      \ 
      =
      \ 
      \bigcap_{i\in I}  
      \mathrm{ri}(C_i)
    $.
    \item
      Let 
      $
        L\,:\,\R^n \to\  \R^m
      $
      be a linear function. Then
      $
        \mathrm{ri}\,L(C)
        \ 
        =
        \ 
        L(\mathrm{ri}\,C)
      $.
      If it also holds
      $
        L^{\!-1}(\mathrm{ri}\,C)
        \ 
        \neq
        \ 
        \emptyset
      $,
      we have
      $
      \mathrm{ri}\,L^{\!-1}(C)
      \ 
        =
      \ 
        L^{\!-1}(\mathrm{ri}\,C)
      $.
      \item
        $
          \mathrm{ri}(C_1\!\times C_2)
          \ 
          = 
          \ 
          \mathrm{ri}\,C_1
          \! 
          \times
          \mathrm{ri}\,C_2
        $
      \item
        $
          \mathrm{ri}(C_1)
          \cap
          \mathrm{ri}(C_2)
          =
          \emptyset
        $
        if and only if
        $
          0 \notin
          \mathrm{ri}
          (C_1 - C_2)
          .
        $
\end{enumerate}

\end{proposition}


\begin{proof}
  For a proof of (i)-(vi) we refer to~\cite[Theorem 6.2 - 6.7]{Rockafellar1970}.

To prove (vii) we use (iv).
Let
  $
  (z_1, z_2)
  \in 
  \mathrm{ri}(C_1\!\times C_2).
  $
  Then for all 
  $
  (x_1, x_2)
  \in 
  C_1\!\times C_2
  $
  there exists
  $t>0$
  such that
  \begin{gather}
    \label{cv:primer:prop:1}
      z_i + t (z_i-x_i)
      \in C_i
      \qquad
      \text{for all}\ 
      i\in \left\{ 1,2 \right\}.
  \end{gather}
  Using (iv) again, we get
  $
  \mathrm{ri}(C_1\!\times C_2)
  \, 
  \subseteq
  \,
          \mathrm{ri}\,C_1
          \! 
          \times
          \mathrm{ri}\,C_2
  $.
  Suppose 
  $
  (z_1,z_2)
    \in
    \mathrm{ri}\,C_1
    \!
    \times
    \mathrm{ri}\,C_2
  $.
  By (iv), for all
  $
    (x_1,x_2)\in C_1\times C_2
  $
  there exist
  $
    (t_1,t_2)>0
  $
  such that
  \begin{gather}
    \label{cv:primer:prop:2}
      z_i + t_i (z_i-x_i)
      \in C_i
      \qquad
      \text{for all}\ 
      i\in \left\{ 1,2 \right\}.
  \end{gather}
  If $t_1=t_2$
  we recover
  \eqref{cv:primer:prop:1}
  from
  \eqref{cv:primer:prop:2}.
  By (iv) it holds
  $
  (z_1,z_2)
    \in
    \mathrm{ri}
    (C_1
    \!
    \times
    C_2)
  $.
  If
  $t_1<t_2$
  we
  define $\theta:=\frac{t_1}{t_2}\in (0,1).$
  Consider  
  \eqref{cv:primer:prop:2} with $i=2$,
  together with $z_2 \in C_2$
  and
  the convexity of $C_2$.
  It follows
  \begin{gather}
    \label{cv:primer:prop:3}
    z_2 + t_1 (z_2 - x_2)
    \ 
    =
    \ 
    \theta
    \cdot
    (
    z_2 + t_2 (z_2 - x_2)
    )
    \ 
    +
    \ 
    (1-\theta)
    \cdot
    z_2
    \in C_2
    \,.
  \end{gather}
  Now we consider
  \eqref{cv:primer:prop:3} and
  \eqref{cv:primer:prop:2} with $i=1$.
  This gives \eqref{cv:primer:prop:1} with $t=t_1$.
  As before, it follows
  $
  (z_1,z_2)\in\mathrm{ri}(C_1\!\times C_2)
  $.
  If 
  $t_1>t_2$
  similar arguments lead to the same result.
  We have proven 
  $
  \mathrm{ri}(C_1\!\times C_2)
  \, 
  \supseteq
  \,
          \mathrm{ri}\,C_1
          \! 
          \times
          \mathrm{ri}\,C_2
  $
  and equality.
    \cite[Theorem~2.92]{Mordukhovich2022}
\end{proof}
 
We procede with convex separation results which are vital to the subsequent developments.

\begin{definition}
  Let 
  $C_1$ and $C_2$
  be two non-empty convex sets in $\R^n$. 
  A hyperplane $H$ is said to \textbf{separate}
  $C_1$ and $C_2$
  if $C_1$ is contained in one of the closed half-spaces associated with
  $H$ and $C_2$ lies in the opposite closed half-space. It is said to separate 
  $C_1$ and $C_2$
  \textbf{properly} if 
  $C_1$ and $C_2$
  are not \textit{both} actually contained in $H$ itselef.
\end{definition}
\begin{theorem}
  Let $C_1$ and $C_2$ be two non-empty convex sets in $\R^n$. 
  There exists a hyperplane separating
  $C_1$ and $C_2$
  properly 
  if and only if
  there exists a vector $b\in \R^n$ such that
  \begin{gather}
    \sup_{x\in C_2} \inner{x}{b}
    \le
    \inf_{x\in C_1} \inner{x}{b}
    \quad 
    \text{and}
    \quad 
    \inf_{x\in C_2} \inner{x}{b}
    <
    \sup_{x\in C_1} \inner{x}{b}
    .
  \end{gather}
\end{theorem}
\begin{proof}
  \cite[Theorem~11.1]{Rockafellar1970}
\end{proof}
\begin{ftheorem}
  \label{cv:primer:sep}
  \emph{(Convex separation in finite dimension)}
  Let $C_1$ and $C_2$ be two non-empty convex sets in $\R^n$. 
  Then $C_1$ and $C_2$ can be properly separated if and only if 
  $\mathrm{ri}(C_1)\cap\mathrm{ri}(C_2)=\emptyset.$
\end{ftheorem}
\begin{proof}
  \cite[Theorem~11.3]{Rockafellar1970}
\end{proof}




\begin{definition}
  Given a nonempty subset 
  $\Omega \subseteq \R^n$
  the \textbf{support function} 
  $
  \sigma_\Omega : \R^n \to \overline{\R}
  $
  of $\Omega$
  is defined by
  \begin{gather}
    \sigma_\Omega
    (x^*)
    :=
    \sup_{x \in \Omega}
    \ 
    \inner{x^*}{x}
    \qquad
    \text{for}\ 
    x^* \in \R^n
    .
  \end{gather}
\end{definition}


\begin{definition}
  Given functions
  $
    f_i:
    \R^n \to (-\infty, \infty]
  $
  for $ i = 1, \ldots, m $
  the \textbf{infimal convolution} of these functions is defined as
  \begin{gather}
    (f_1 \square \cdots \square f_m)(x)
    \ 
    :=
    \ 
    \inf
    \left\{ 
    \sum_{i = 1}^{m}
      f_i(x_i)
      \ 
      \colon
      \ 
      x_i \in \R^n 
      \ 
      \mathrm{and}\ 
      \sum_{i = 1}^{m} 
        x_i
      =
      x
    \right\}
  \end{gather}
\end{definition}
 
The next result establishes a connection between the support function of the intersection of two convex sets and the infimal convolution of the support functions of the sets taken by themselfes.
The proof translates the geometric concept of convex separation to the world of convex functions.

\begin{lemma}
  \label{cv:primer:lem}
  Let $C_1$ and $C_2$ be two non-empty convex sets in $\R^n$.
  For any
  $ x^* \in \mathrm{dom}\, \sigma_{C_1\cap C_2} $
  the sets
  \begin{align*}
    \Theta_1
    &
    \ :=\ 
    C_1 \times [\,0,\infty)
    \,,
    \\
    \Theta_2
    (x^*)
    &
    \ :=\ 
    \left\{ 
      (x,\lambda)\in \R^n
      \ 
      \colon
      \ 
      x \in C_2
      \ 
      \text{and}
      \ 
      \lambda
      \,
      \le
      \,
      \inner{x^*\!}{x} 
      \ 
      -
      \ 
      \sigma_{C_1\cap C_2}(x^*)
    \right\}
  \end{align*}
  can by properly separated.
\end{lemma}
\begin{proof}
  We fix 
  $ x^* \in \mathrm{dom}\, \sigma_{C_1\cap C_2} $
  and write
  $ 
  \alpha
  \ 
  :=
  \ 
  \sigma_{C_1\cap C_2}(x^*)
  $.
  In order to apply convex separation in finite dimension 
  (Theorem~\ref{cv:primer:sep})
  to
  the sets
  $ \Theta_1 $ and $ \Theta_2(x^*) $,
  it suffics to show
  their convexity and
  $
    \mathrm{ri}\, 
    \Theta_1
    \cap
    \mathrm{ri}\, 
    \Theta_2(x^*)
    =
    \emptyset
  $.
  \subsubsection*{Convexity of 
  $ \Theta_1 $ and $ \Theta_2(x^*) $
  }
  Clearly, 
  $ \Theta_1 $ is convex by the convexity of 
  $ C_1 $ and $ [0,\infty) $.
 To see that $\Theta_2(x^*)$ is convex consider the linear function
 \begin{gather*}
    L
    \,
    :
    \,
    \R^n\times\,  \R 
    \ 
    \to
    \ 
    \R
    \,,
    \qquad 
    (x,\lambda)
    \ 
    \mapsto
    \ 
    \inner{x^*\!}{x} - \lambda
    \,.
 \end{gather*}
 From the definitions of $L$ and $\Theta_2(x^*)$ we get 
  \begin{gather*}
 \Theta_2
 (x^*)
    \ 
    =
    \ 
    (
    C_2\!\times\R
    )
    \ 
    \cap
    \ 
    L^{\!-1}
    [\,\alpha,\infty)
    \,
    .
  \end{gather*}
  Thus,
  by
  Proposition~\ref{cv:primer:prop}~(v)
  and the convexity of $C_2$ we get the convexity of
  $
    L^{\!-1}
    [\,\alpha,\infty)
  $ and with it that of $\Theta_2(x^*)$.

  \subsubsection*{Relative interiors of
  $ \Theta_1 $ and $ \Theta_2(x^*) $
  are disjoint}
  We start by calculating the relative interiors. It holds
  \begin{alignat*}{3}
    \mathrm{ri}\,
    \Theta_1
    &
    \ 
    =
    \ 
    \mathrm{ri}
    ( C_1\times [0,\infty) )
    &&
    \ 
    =
    \ 
    \mathrm{ri}\,
    C_1
    \!
    \times
    \mathrm{ri}\,
    [0,\infty)
    \ 
    =
    \ 
    \mathrm{ri}\,
    C_1
    \!
    \times
    (0,\infty)
    \,,
    %%%%%%%%%%%%%%%%%
    \\
    \mathrm{ri}\,
    \Theta_2(x^*)
    & 
    \ 
    =
    \ 
    \mathrm{ri}
    (
    L^{\!-1}
    [\,\alpha,\infty)
    )
    &&
    \ 
    =
    \ 
    L^{\!-1}
    (
    \mathrm{ri}\,
    [\,\alpha,\infty)
    )
    \ 
    \ 
    =
    \ 
    L^{\!-1}
    (\alpha,\infty)
    \,.
  \end{alignat*}
  Suppose there exists
  $ (\lambda,x) \in
    \mathrm{ri}\, 
    \Theta_1
    \cap
    \,
    \mathrm{ri}\, 
    \Theta_2(x^*)
  $.
  Then it holds 
  $ x \in C_1\!\times C_2 $
  and 
  $ \lambda >0 $.
  We also note, that
  \begin{gather*}
  \alpha
  \ 
  =
  \ 
  \sigma_{C_1\cap\, C_2}(x^*)
    \ 
  =
    \ 
  \sup_{z \in C_1\cap\, C_2}
  \inner
  {x^*}
  {z}
  \ 
  \ge
  \ 
  \inner
  {x^*}
  {x}
  \,.
  \end{gather*}
  Then it follows
  \begin{gather*}
    \alpha
    \ 
    <
    \ 
  \inner
  {x^*}
  {x}
  - \lambda
    \ 
  \le
    \ 
  \alpha\,,
  \end{gather*}
  a contradiction.
  Thus, the relative interiors of
  $ \Theta_1 $ and $ \Theta_2(x^*) $
  are disjoint.

  Applying Theorem~\ref{cv:primer:sep} finishes the proof.
\end{proof}


\begin{theorem*}
  Let $C_1$ and $C_2$ be two non-empty convex sets in $\R^n$ with
  $\mathrm{ri}\,C_1\cap\mathrm{ri}\,C_2\neq\emptyset.$
  Then the support function of the intersection 
  $
    C_1\! \cap C_2
  $
  is represented as
  \begin{gather}
    (\sigma_{
    C_1 \cap\, C_2
    })
    (x^*)
    =
    (\sigma_{C_1}\square \,\sigma_{C_2})
    (x^*)
    \qquad
    \text{for all}\ 
    x^* \in \R^n.
  \end{gather}
  Furthermore, for any
  $
  x^*\in \mathrm{dom}
    (\sigma_{
    C_1 \cap\, C_2
    })
  $
  there exist dual elements 
  $
    x_1^*
    ,
    x_2^*
    \in \R^n
  $ 
  such that 
  $
    x^*
    =
    x_1^*
    +
    x_2^*.
  $
  and
  \begin{gather}
    (\sigma_{
    C_1 \cap\, C_2
    })
    (x^*)
    =
    \sigma_{C_1}(x_1^*)
    +
    \sigma_{C_2}(x_2^*).
  \end{gather}
\end{theorem*}
\begin{proof}
  Using Lemma~\ref{cv:primer:lem}
  the rest of the proof is as that of
  \emph{\cite[Theorem~4.23(b)]{Mordukhovich2022}}.
\end{proof}

\begin{takeaways}
  The support function intersection rule connects the geometric 
  property of convex separation to an identity of support functions
  This result is central to the analysis of convex conjugates.
\end{takeaways}
