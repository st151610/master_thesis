We present the relevant parts of the paper \cite{Bertsekas2003}.
\begin{fproblem}
  \label{cv:ts:primal}
\begin{align*}
  %%%% objective %%%%
    &\underset{x \in \R^n}
    {\text{minimize}}
    &&\qquad\qquad
    f(x)
    &&&
    \\
    %%%% Ax >= b %%%%
    &\text{subject to}
    &&\qquad\qquad
    \mathbf{A}x
    \ 
    \ge
    \ 
    b
    \,.
\end{align*}
\end{fproblem}
\begin{assumptions*}
  \begin{enumerate}[label={(\roman*)}]
    Assume that the map 
    $
      f: \R^n \to \overline{\R}
    $
    has the following properties.
    \item
      $
        f 
        \ 
        \text{is strictly convex.}
      $
    \item
      $
        f
        \ 
        \text{is lower-semicontinuous and continuous on}
        \ 
        \mathrm{dom}\,f
        .
      $
    \item
      $
        \text{The convex conjugate}
        \ 
        f^*
        \ 
        \text{of}\ 
        f
        \ 
        \text{is finite}
        .
      $
  \end{enumerate}
\end{assumptions*}

The dual optimization problem of Problem~\ref{cv:ts:primal} 
is
\begin{fproblem}
  \label{cv:ts:dual}
  \begin{alignat*}{2}
  %%%% objective %%%%
    &\underset{y \in \R^m}
    {\text{maximize}}
    &&\qquad\qquad
    \inner
    {y}
    {b}
    \ 
    -
    \ 
    f^*
    ( A ^ \top y )
    \\
    %%%% Ax >= b %%%%
    &\text{subject to}
    &&\qquad\qquad
    y
    \ 
    \ge
    \ 
    0
    \,.
\end{alignat*}
\end{fproblem}
Let $q$ denote the objective function of Problem~\ref{cv:ts:dual},
that is,
\begin{gather}
  q
  \, 
  : 
  \, 
  \R^m  \to\  \R\,,
  \qquad
  y
  \ 
  \mapsto
  \ 
  \inner
    {y}
    {b}
    \, 
    -
    \, 
    f^*
    ( A ^ \top y )
  \,.
\end{gather}
q is concave.
The dual problem $(D)$ is a concave program
with nonnegativity constraints on the dual variable $y_a$
of the inequality constraints in $(P)$.
Furthermore, strong duality holds for $(P)$ and $(D)$,
that is, they have the same optimal value.

Since $f^*$ is real-valued and $f$ is strictly convex, 
$f^*$ and $q$ are continuously differentiable~(cf.\cite[Theorem~26.3]{Rockafellar1970}).
\begin{theorem*}
  \emph{}
  A closed proper convex function is strictly convex
  if and only if its conjugate is continuously differentiable.
\end{theorem*}
\todo[color=green!40, inline]{What does closed mean and does $f$ meet this condition?}

We will denote the gradient of $q$ at $p$ by $d(p)$
and its $i$th coordinate by $d_i(p).$
Since $q$ is continuously differentiable, $d_i(p)$ is continuous.

By differentiating and using the chain rule, 
we obtain the dual cost gradient
\begin{gather}
  \label{cv:ts:1}
  d(p)=b-\mathbf{A}x,
  \quad
  \text{where}
  \quad
  x:=
  \nabla
  f^*
  (
    \mathbf{A}^\top
    p
  )
  =
  \mathrm{argsup}
  _{\xi \in \R^m}
  \inner{p}{\mathbf{A}\xi}
  - f(\xi)
  .
\end{gather}
The last equality follows from Danskin's Theorem and \cite[Theorem~23.5]{Rockafellar1970}


\begin{proposition*}
  \emph{(Danskin's Theorem \cite[page 649]{Bertsekas2003})}
  Let 
  $
    Z \subseteq \R^m
  $
  be a non-empty set, 
  and let 
  $
    \phi :
    \R^n \times Z \to \R
  $
  be a continuous function such that
  $
    \phi(\cdot,z)
    :
    \R^n \to \R,
  $
  viewed as a function of its first argument, 
  is convex for each 
  $
    z \in Z.
  $
  Then the function 
  \begin{gather}
    f:\R^n \to \R
    ,
    \qquad
    x\mapsto
    \sup_{z\in Z}
    \phi(x,z)
  \end{gather}
  is convex and has directional derivative given by
  \begin{gather}
    f^{'}(x;y)
    =
    \sup_{z \in Z(x)}
    \phi^{'}(x,z; y)
    ,
  \end{gather}
  where 
  $
    \phi^{'}(x,z; y)
  $
  is the directional derivative of the function 
  $
    \phi(\cdot,z)
  $
  at
  $x$ in the direction $y,$
  and
  \begin{gather}
    Z(x)
    :=
    \left\{ 
      \overline{z} \in \R^m
      \colon
      \phi(x, \overline{z})
      =
    \sup_{z\in Z}
    \phi(x,z)
  \right\}
  .
  \end{gather}
  In particular, if $Z(x)$ consists of a unique point 
  $\overline{z}$
  and
  $
    \phi(\cdot, \overline{z})
  $
  is differentiable at $x,$
  and 
  $
    \nabla f(x)
    =
    \nabla_x
    \phi(x,\overline{z})
    ,
  $
  where 
  $
    \nabla_x
    \phi(x,\overline{z})
  $
  is the vector with coordinates
  $
    (\partial \phi / \partial x_i)
    (x,\overline{z})
  $
\end{proposition*}
Note that $x$ is the unique vector satisfying 
\begin{gather}
  \mathbf{A}^\top p
  \in 
  \partial
  f(x)
  \,.
\end{gather}

In the following let $p$ be an optimal solution to 
Problem~\ref{cv:ts:dual}.
\subsection*{Complementary Slackness}
We show that for all 
$
  i\in \left\{ 1,\ldots, n \right\}
$
it holds
\begin{alignat*}{2}
  \text{either}
  &
  &&
  \qquad
  p_i = 0
  \quad
  \text{and}
  \quad
  d_i(p) \le 0
  \\
  \text{or}
  &
  &&
  \qquad
  p_i > 0
  \quad
  \text{and}
  \quad
  d_i(p) = 0
  \,.
\end{alignat*}
Assume towards a contradiction that $d_i(p)>0$ for some 
$
  i\in \left\{ 1,\ldots, n \right\}
$.
Consider
the $\mu$ perturbation of $p$ in the $i$-th coordinate, that is,
\begin{gather}
  \tilde{p}
  (\mu)
  :=
  p
  +
  e_i
  \cdot
  \mu
  \,.
\end{gather}
By the continuity of $d_i$ there exists $\mu >0$ such that
$
d_i(
  \tilde{p}
  (\mu)
)
>0$.
By the concavity of $q$ it follows
\begin{gather}
  \label{cv:ts:cs:1}
  q
  (
  \tilde{p}
  (\mu)
  )
  -
  q(p)
  \ge
d_i(
  \tilde{p}
  (\mu)
)
\cdot
\mu
>0
\,.
\end{gather}
Since
$ 
  \tilde{p}
  (\mu)
  )
  \ge
  0
$
this is a contradiction to the optimality of $p$ in Problem~\ref{cv:ts:dual}. 
Thus
$
  d_i(p)\le 0
$
for all 
$
  i\in \left\{ 1,\ldots, n \right\}
$.
Now assume that
$ p_i>0 $ and 
$
  d_i(p)< 0
$
for some
$
  i\in \left\{ 1,\ldots, n \right\}
$.
Again, by the 
continuity of $d_i$ there exists $\mu <0$ such that
$
d_i(
  \tilde{p}
  (\mu)
)
<0$
and
$
p_i+\mu >0
$.
But then it follows \eqref{cv:ts:cs:1}.
We have shown the complementary slackness of $p$ and $d(p)$.

To obtain the primal solution by a dual solution we use results
of Karush-Kuhn-Tucker.
%Given an optimal dual solution $p$,
%we may obtain an optimal primal solution from the equation 
%$
%  x=
%  \nabla
%  f^*
%  (
%    \mathbf{A}^\top
%    p
%  )
%.
%$
%To see this, 
%note that 
% \begin{gather}
%   \mathbf{A}x \ge b
%   \quad
%   \text{and}
%   \quad
%   p_i 
%   =
%   0
%   \quad 
%   \text{for all}
%   \ 
%   i
%   \ 
%   \text{such that}
%   \quad 
%   \sum_{j=1}^{m} 
%   a_{ij}
%   x_j
%   >
%   b_i
%   .
% \end{gather}
%
% We can show that $p$ and $x$ satisfy the KKT conditions and thus $x$ is an optimal solution to $(P)$.
%
%n 
%
\begin{definition*}
  \emph{\cite[ยง28]{Rockafellar1970}}
  By an \textbf{ordinary convex program}
  $(P)$
  we mean an optimization problem of the following form
  \begin{gather*}
    \underset{x\in C}{\mathrm{minimize}}
    \qquad
    f_0(x)
  \end{gather*}
subject to the constraints
\begin{gather}
  f_1(x)\le 0,
  \ldots,
  f_r(x)\le 0,
%  \qquad
%  f_{r+1}(x)= 0,
%  \ldots,
%  f_m(x)= 0,
\end{gather}
where $C\subseteq \R^n$
is a non-empty convex set and
$f_i$ is a finite convex function on $C$ for $i\in \left\{ 1,\ldots,r \right\}$.
% and 
% $f_i$ is an affine function on $C$ for $i\in \left\{ r+1, \ldots, m \right\}.$
\end{definition*}

%\begin{definition}
%  We define 
%  $
%    [\lambda_1, \ldots, \lambda_m]\in \R^m
%  $
%  to be a \textbf{Karush-Kuhn-Tucker (KKT) vector}
%  for $(P)$, if
%  \begin{enumerate}[label={(\roman*)}]
%    \item
%      $
%        \lambda_i \ge 0
%        \ 
%        \text{for all}
%        \ 
%        i\in \left\{ 1,\ldots,r \right\}.
%      $
%    \item
%      The infimum of the proper convex function 
%      $
%        f_0
%        +
%        \sum_{i=1}^{m}
%        \lambda_1 f_i
%      $
%      is finite and equal to the optimal value in $(P).$
%  \end{enumerate}
%\end{definition}
%
\begin{ftheorem}
  \label{cv:ts:kkt}
  \emph{(Karush-Kuhn-Tucker conditions)}
  Let $(P)$
  be an ordinary convex program,
  $
  \overline{\alpha}
  \in \R^m
  $,
   and 
   $
   \overline{z}
   \in \R^n.
   $
   Then 
%   $
%  \overline{\alpha}
%   $
%   is a KKT vector for $(P)$
%   and 
   $
   \overline{z}
   $
   is an optimal solution to $(P)$
   if  
   $
   \overline{z}
   $
   and 
   the components $\alpha_i$ of
   $
  \overline{\alpha}
   $
   satisfy 
   the following conditions.

  \begin{enumerate}[label={(\roman*)}]
    \item
      $
        \alpha_i \ge 0,
        \ 
        f_i(
   \overline{z}
        )
        \le 0,
        \ 
        \text{and}
        \ 
        \alpha_i 
        f_i(
   \overline{z}
        )
        =0
        \ 
        \text{for all}
        \ 
        i\in \left\{ 1, \ldots, r \right\}
      $.
%      \item
%        $
%        f_i(
%   \overline{z}
%        )
%        =0
%        \ 
%        \text{for}
%        \ 
%        i\in \left\{ r+1, \ldots, m \right\}
%        .
%        $
      \item
        $
         0
         _n
         \in 
         [
          \partial
        f_0(
   \overline{z}
        )
        +
        \sum_{\alpha_i\neq 0}
        \alpha_i 
        \partial
        f_i(
   \overline{z}
        )
         ]
.
        $
  \end{enumerate}
\end{ftheorem}
\begin{proof}
  \cite[Theorem~28.3]{Rockafellar1970}
\end{proof}
\subsubsection*{Karush-Kuhn-Tucker conditions}
Problem~\ref{cv:ts:primal} is an ordinary convex program with
$
f_0=f
$
and
$
f_i(x)
=
 b_i
 -
\sum_{j=1}^{n} 
a_{ij}x_j
$.
From \eqref{cv:ts:1}
it follows
$
f_i(x)=d_i(p)\le 0
$.
From the complementary slackness it follows
$
p_i\cdot f_i(x)=p_i \cdot d_i(p)= 0
$.
Let $x^* \in \R^n$.
It holds
\begin{align}
  \inner
  {
    - \mathbf{A}^\top
    e_i
  }
  {
    x^*-x
  }
  =
  \inner{e_i}
  {
    \mathbf{A}
    x
  }
  -
  \inner{e_i}
  {
    \mathbf{A}
    x^*
  }
  =
  f_i(x^*)
  -
  f_i(x)
  \,.
\end{align}
Thus 
$
    - \mathbf{A}^\top
    e_i
$
is a subgradient of $f_i$ at $x$, that is,
$
    - \mathbf{A}^\top
    e_i
    \in
    \partial
    f_i(x)
$.
By 
$
    \mathbf{A}^\top p
    \in
    \partial
    f(x)
$
it follows
\begin{gather}
  0
  =
    \mathbf{A}^\top p
    -
    \sum_{p_i\neq 0} 
    p_i 
     \mathbf{A}^\top
     e_i
     \in
         [
          \partial
        f_0(
   \overline{x}
        )
        +
        \sum_{p_i\neq 0}
        p_i 
        \partial
        f_i(
   \overline{x}
        )
         ]
         \,.
\end{gather}
Thus, by Theorem~\ref{cv:ts:kkt}, 
\begin{gather}
x=
  \nabla
  f^*
  (
    \mathbf{A}^\top
    p
  )
\end{gather}
is an optimal solution to Problem~\ref{cv:ts:primal}. 
Since
$f$ is strictly convex, this solution is the only one.
\begin{takeaways}
  Employing the Karush-Kuhn-Tucker conditions, we
  derive a dual relationship between optimal solutions
  for strictly convex functions.
\end{takeaways}
