\begin{theorem}
  Under conditions
  \begin{gather}
    \P
    \left[ 
      \norm{\lambda^\dagger - \lambda^*}
      \le
      C_\P
      C_\tau
      \varepsilon_n
    \right]
    \ge
    1-\tau
    \,,
  \end{gather}
  where 
  $\varepsilon_n$ is the square root of the basis function Learning rate and $C_\tau$ depends on the Concentration Inequality.
  We need bernstein confidence $\sqrt{\log (1/\tau)}$ to preserve minimal Learning rate for $d=1$.
\end{theorem}
