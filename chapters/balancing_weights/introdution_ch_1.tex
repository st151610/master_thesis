We work in the Rubin Causal Model.

We assume a sample of $n$ units which is drawn from a population distribution.

In i.i.d. fashion.

We observe $ (\mathbf{X}_i, T_i, Y_i) $,
where $\mathbf{X}$ are covariates, 
$T$ is the indicator if treatment has been received
and $Y$ is the observed outcome.

In the Rubin Causal Model we assume that for each unit the potential outcome exist, i.e. $(Y_i^0, Y_i^1)$ where $Y^1$ stands for the potential outcome had the unit received treatment and $Y^0$ for the potential outcome had the unit received \textbf{no} treatment.

It is clear that $Y_i = Y_i^{T_i}$ i.e. we can observe only one of the potential outcomes.

Thus there is a connection to missing data problems.

This is the dilemma of causal inference.
 
On the population level it is possible to estimate both.

Usually the means of the potential outcomes are compared against each other.

In randomized trials this is a valid approach to causal inference.

In observational studies however the treatment assignment is not known and direct comparison can lead to systematically wrong results.

This phenomenon is called \textbf{confounding}.
 
To address the issue of confounding many methods have been proposed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

An intuitive way to think about potential outcomes is to think of a stochastic process $Y(\cdot)$ indexed over $\left\{ 0,1 \right\}$.
By observing $Y_i$ we in fact sample from this process at random index $T$, i.e. from $Y(T)$.
We have 
\begin{gather}
  \E[Y(T)]
  =
  \E[Y(1) \vert T=1] \P[T=1]
    +
  \E[Y(0) \vert T=0] \P[T=0]
  .
\end{gather}
Suppose we observe $T=1$. Clearly we have
\begin{gather}
  \E[Y(T)\vert T=1]
  =
  \E[Y(1) \vert T=1] 
\end{gather}
