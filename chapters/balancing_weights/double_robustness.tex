%read the paper \cite{Zhao2017a} for discussion of double robustness for balancing weights and \cite{Hahn1998} for semiparametric efficiency bounds.

By double robustness we mean the property of an estimator that it is consistent if either one of treatment or outcome model is well specified.
The augmented weighting estimator was designed to have exactly this property.
Surprisingly, the weighted mean estimator in the balancing weights approach of \cite{Wang2019} retains this feature despite its simplicity \cite{Zhao2017a}. 
In the following we explore double robustness in the weighted mean estimator from the perspective of learning rates.
We will adopt a similar notion of learning rates as in \cite{Steinwart2008}.
To the best of our knowledge this approach is new.
We investigate how learning rates change in different scenarios. 
\subsection{Learning Rates of the weighted mean}

What is the speed of convergence in the weak law of large numbers?
A clear-cut answer is:
The arithmetic mean of independent, identically distributed, square-integrable random variables 
learns with rate $n^{-1/2}$.
Furthermore, using
Bienaymé's formula and Chebyshev's inequality, the statement is easy to prove~(cf. \cite[Theorem~5.14]{Klenke2020}).


\begin{theorem*}
  Let 
  $
    X_1,X_2,\ldots
  $
  be i.i.d, square-integrable random variables with 
  $
    V:=
    \mathbf{Var}[X_1]
    <\infty
  $.
  Then, for any $\tau \in (0,1]$ and all $n\in\mathbb{N}$, we have
  \begin{gather}
   \P
   \left[
     \left| 
   \frac{1}{n}
   \sum_{i=1}^{n}
   (X_i - \E[X_i])
     \right|
     \le
     \sqrt{V}
     \frac{1}{\sqrt{\tau}}
     \frac{1}{\sqrt{n}}
   \right]
   \ge
   1-\tau\,.
  \end{gather}
\end{theorem*}
\begin{reflection*}
  Bernsteins's inequality yields better confidence.
\end{reflection*}

\begin{theorem}
  \emph{(Bernstein's inequality)}
  Let
  $
  (\Omega,\mathcal{A},\P)
  $ 
  be a probability space, 
  $
  B>0
  $ 
  and
  $
  \sigma>0
  $
  be real numbers,
  and
  $
  n\ge 1
  $
  be an integer.
  Furthermore, 
  let
  $
  X_1,\ldots,X_n
  :
  \Omega
  \to
  \R
  $
  be independent random variables satisfying
  $
  \E[X_i]=0
  $,
  $
  \norm{X_i}_\infty
  \le
  B
  $
  and
  $
  \E[X_i^2]\le \sigma^2
  $
  for all 
  $
  i=1,\ldots,n
  $.
  Then we have
  \begin{gather*}
    \P
    \left[ 
      \,
      \left| 
      \frac{1}{n}
        \sum_{i=1}^{n} 
        X_i
      \right|
      \ 
      \le
      \ 
      \sqrt{
        \,
        \frac{2\,\sigma^2 \log (e/\tau)}{n}
        \,
      }
      \ 
      +
      \
      \frac{2 B \log(e/\tau)}{3n}
      \,
    \right]
    \ 
    \ge
    \ 
    1-\tau
    \,
    ,
    \qquad
    \tau>0\,.
  \end{gather*}
\end{theorem}
\begin{proof}
  Confer \cite[Theorem~6.12]{Steinwart2008}
  for the one-sided version. 
  The two-sided version, as stated in the above theorem, is an easy consequence. We omit the details.
\end{proof}
$
\sqrt{2}(\sigma\lor B)\frac{1}{\sqrt{n}}
\log(e/\tau)
$

We conflate \textit{observed outcomes} 
with
~\textit{
marginal potential outcomes}.
%, that is,
%\begin{gather}
%  Y(1)\,|\,T=1
%  \ 
%  \sim 
%  \ 
%  \P_
%  {
%  Y(1)
%  }
%  \,.
%\end{gather}
But few study populations allow for such disregard.
If, by chance, we compare the health of 
systematically different persons, such as
that of a thriving smoker with that of an asthmatic non-smoker,
the conclusion leads us astray.
Smoking is not healthy.
\textbf{Confounders}, as the literature calls 
unbalanced external influences
on both treatment and outcome,
are lurking in the data.
The term
\textit{Simpson's paradox} 
is a collection of painful stories telling about surprising changes of effect in subclasses of the data~(cf.\cite{Wagner1982} for a brief discussion of Simpson's paradox and some real world examples).
The probabilistic tools of the community were not sharp enough,
so non-probabilistic frameworks, like causal framework,
found widespread acceptance. 
Their proper use in empirical data analysis is, however, still subject to debate~\cite[§6]{pearl2009causality}.


In experimental studies we usually specify treatment assignment as opposed to merely observing a unit receiving treatment. 

The next statement makes use of the propensity score.

\begin{theorem*}
  Consider the weighted mean estimator with weights
  \begin{gather}
    w_i
    \ 
    =
    \ 
    \frac{1}{n}
    \frac{T_i}{\pi(X_i)}
    \,.
  \end{gather}
  Denote
  $
    V:=
    \E[
    (
      Y(1)
    )^2
    \,/\,
    \pi(X)
    ]
    -
    \E[Y(1)]^2
  $.  
  Assume that \textit{weak unconfoundedness} holds.
  Then, for any $\tau \in (0,1]$ and all $n\in\mathbb{N}$, we have
  \begin{gather}
   \P
   \left[
     \,
     \left| 
     \,
   \sum_{i=1}^{n}
   w_iY_i - \E[Y(1)]
   \,
     \right|
     \ 
     \le
     \ 
     \sqrt{V}
     \frac{1}{\sqrt{\tau}}
     \frac{1}{\sqrt{n}}
     \,
   \right]
   \ 
   \ge
   \ 
   1-\tau\,.
  \end{gather}

\end{theorem*}
\begin{proof}
We want to reinforce coherent use of the weak law of large numbers.
To this end, we verify 
\begin{align*}
  n\,\E[w(T,X)\,Y(T)]
  \ 
  &=
  \ 
  \E[Y(1)]
  \,,
  \\
  n^2\,
  \mathbf{Var}[w(T,X)\,Y(T)]
  \ 
  &=
  \ 
    \E[
    (
      Y(1)
    )^2
    \,/\,
    \pi(X)
    ]
    -
    \E[Y(1)]^2
    \,.
\end{align*}
Essentially, the random weight $w(T,X)$ acts on $Y(T)$ through $T\,/\,\pi(X)$.
It does so by inducing independence of observed outcome $Y(T)$ and treatment $T$.
This requires that weak unconfoundedness holds, i.e., 
\begin{gather}
  (Y(0),Y(1))\perp\!\!\!\perp T\, |\, X\,.
\end{gather}
To showcase the details we added an $n$ and $n^2$ factor in the above display.
The calculations go as follows.
\begin{align}
  \begin{split}
  n\,\E[w(T,X)\,Y(T)]
  &\ 
  =
  \ 
  \E
  \left[ 
    Y(T)
    \cdot
    (T\,/\,\pi(X))
  \right]
  \\
  &\ =\ 
  \E
  \left[ 
    Y(1)
    \,
    /
    \,
    \pi(X)
    \,
    \vert
    \,
    T=1
  \right]
  \cdot
  \P[T=1]
  \\
  &\ =\ 
  \int_\mathcal{X}
  \E
  \left[ 
    Y(1)
    \,
    \vert
    \,
    X=x
    ,
    T=1
  \right]
  \cdot
  (
  \P[T=1]
  \,
  /
  \,
  \pi(x)
  )
  \,
  \P_{X|T}(dx\,|\,1)
  \\
  &\ =\ 
  \int_\mathcal{X}
  \left[ 
    Y(1)
    \vert
    X=x
  \right]
  \P_X(dx)
  =
  \E[Y(1)]
  .
\end{split}
\end{align}
The first equality holds because of the definition of the weights.
The second, third and last equality stem from 
$
  T\in \left\{ 0,1 \right\}
$,
and the law of total expectation, applied with $T$ and $X$.
The fourth equality is justified by the assumption of weak unconfoundedness.
The density transformation is due to Bayes's Theorem.
With slight modifications in the above argument, it follows
\begin{gather}
  \E
  \left[ 
  \Big( 
    Y(T)
    \cdot
    (T\,/\,\pi(X))
  \Big)
  ^2
  \right]
  \ 
    =
    \ 
    \E
    \Big[
    (Y(1))^2
    \,
    /
    \,
    \pi(X)
    \Big]
    \,.
\end{gather}
We omit the details.
Invoking the weak law of large numbers finishes the proof.
\end{proof}
\todo[color=orange!40,inline]{Formulate improved version with Bernstein.}

\todo[color=orange!40,inline]{Formulate better transition to weights with estimated propensity score.}
We started by asking an easy question, so it is time for a more challenging one: How do we proceed in deriving learning rates if the propensity score is unknown.
How do we generally procede?
[what has been done in the past. Why are some methods obsolete]
A naive answer would be: We hope to select a proper model and try to estimate the propensity score.
Stunningly, a lot of practicioners still settle for obsolete methods when it comes to propensity score analysis.


Next, we consider the event that we have a consistent estimator of the 
propensity score and the distribution of the covariate vector $X$, 
along with that of the outcome $Y$, 
has compact support.
The next assumptions reduce the technical task to a minimum.

\begin{assumptions*}
  Let the following hold.
  \begin{enumerate}[label={(\roman*)}]
    \item
      There exists $C_Y\ge 1$ such that $|Y(1)|\le C_Y$ almost surely. 
    \item
      There exists $C_\pi > 0$ such that $C_\pi < \pi(X)$ almost surely.
    \item
      There exists a function class $\mathcal{F}$ 
      with unit ball 
      $
        B_\mathcal{F}
        :=
        \left\{ 
          f\in \mathcal{F}
          \colon
          \norm{f}_\infty
          \le 
          1
        \right\}
      $
      such that  
      $
          \log N_{[\,]}(\varepsilon, B_\mathcal{F}, L_2(\P))
        \le
        C_{\mathcal{F}}
        (1/\varepsilon)^{1/k} 
      $
      for some $k>1/2$ and some constant $C_\mathcal{F}\ge 1$.
    \item
      The random function $f_w$ defined by
      $
  f_w(T,X,Y)
  \ 
  :=
  \ 
  \left( 
   n\, w(X)
    \ 
    -
    \ 
    \frac{1}{\pi(X)}
  \right)
  \,
  T
  \,
  Y
      $
      satisfies
      $f_w\in \mathcal{F}$
      almost surely
      .
  \item 
    There exist a learning rate 
    $
    (r_n)
    $,
    confidence constants
    $
    (\gamma_\tau)
    $
    and 
    uniform constant
    $
    C_w\ge 1
    $
    such that
    for all $\tau \in(0,1]$
    and all $n \in \mathbb{N}$
    it holds
    $
    \P
    \left[ 
    \norm{w(X) - \frac{1}{\pi(X)}}_\infty
    \le
    C_w
    c_\tau
    \varepsilon_n
    \right]
    \ge 
    1-\tau
    $
    \item
      There exists $\alpha > 1$ 
  such that 
  $
  \varepsilon_n \cdot c_{n^{-\alpha}}
  \to 
  0
  $
  as 
  $
  n\to \infty
  $
  and 
  $
  \varepsilon_n \cdot c_{n^{-\alpha}}
  \le 
  1
  $
  for all 
  $n \in \mathbb{N}$.
  \end{enumerate}
\end{assumptions*}
\todo[color=orange!40, inline]{Elaborate on assumptions. For example (iii) \cite[§2.7.1]{vaart2013}
  \cite[§19.9]{Vaart2000}
}
\begin{theorem*}
  Let the assumptions.
  Then the weighted mean learns with rate
  $
    (\varepsilon_n)
  $
  defined by
  \begin{gather*}
    \varepsilon_n
    \ 
    :=
    \ 
    \inf
    \left\{ \,t \,\in\,  (\,0,1]
      \ 
      \colon
      \ 
  r_n \cdot \gamma_{\,t/n}
  \ 
  \le
  \ 
  t
  \,
    \right\}
    \ 
    \land 
    \ 
    1
    \qquad
    \text{for all}
    \ 
    n\in \mathbb{N}
    \,.
  \end{gather*}
  Furthermore, it has confidence constants
  $
  (c_\tau)
  $
  given by
\begin{gather}
  c_\tau = \gamma_\tau /\tau
\end{gather}
  and uniform constant
  \begin{gather}
C_\P    
=
\max
\left\{ 
  \sqrt{C_\mathcal{F}}
  C_w
  ,
  C_Y
  C_w
  ,
  \frac{C_Y}{C_\pi}
\right\}
  \end{gather}
\end{theorem*}

\begin{proof}
  We consider the following error decomposition.
\begin{align*}
  \begin{split}
  &\sum_{i=1}^{n}
  \,
  w_i T_i\,Y_i
  \ 
  -
  \ 
  \E[Y\!(1)]
  \\
  &\qquad=
    \ 
    \frac{1}{n}
  \sum_{i=1}^{n}
  \,
    \frac{T_i}{\pi(X_i)}
    \,
  \left(
    Y_i
    -
  \E[Y\!(1)]
  \,
  \right)
  \ +
  \ 
  \sum_{i=1}^{n}
  \,
  T_i
  \left( 
    w_i
    -
    \frac{1}{n\,\pi(X_i)}
    \,
  \right)
  \,
  Y_i
  \\
  & 
  \qquad
  =
  \ 
\frac{1}{n}
  \sum_{i=1}^{n}
  \,
    \frac{T_i}{\pi(X_i)}
    \,
  \left(
    Y_i
    -
  \E[Y\!(1)]
  \,
  \right)
  \\
  &\hspace{60mm}
  +
  \ 
  \frac{1}{\sqrt{n}}
  \,
  \G_n f_w
  \\
  &\hspace{83mm}
  -
  \ 
  \E[
  f_w(T,X,Y)
  \,
  ]
  \,.
  \end{split}
\end{align*}
We already bounded the first term. 
To bound the remaining terms we will use the learning rates of $w$.
To this end, we employ maximal inequalities for empirical processes to bound the second term.
We bound the third term by the law of total expectation and balancing learning rates and confidence.
\subsubsection*{2nd term}
Denote
$
  \mathcal{F}_{n,\tau}
  :=
  (
  C_Y
  C_w
  \gamma_\tau
  r_n
  )
  \cdot
  B_\mathcal{F}
  =:
  \delta_{n,\tau}
  \cdot
  B_\mathcal{F}
$.
It holds by maximal inequalities
\begin{align*}
  \E^*\left[ 
    \norm{\G_n}_{\mathcal{F}_{n,\tau}}
  \right]
  &
  \ 
  \le
  \ 
  \int_0^{\delta{n,\tau}}
  \!\!\!
  \sqrt{
    \,
    \log 
    N_{[\,]}
    \left( 
      \varepsilon / \delta_{n,\tau}
    ,
    B_{\mathcal{F}}
    ,
    L_2(\P)
    \right)
  }
  \,
  d\varepsilon
  \\
  &
  \ 
  \le
  \ 
  \int_0^{\delta_{n,\tau}}
  \!
  \left( 
    \frac{\delta_{n,\tau}}{\varepsilon}
  \right)^{1/(2k)}
  \!
  d \varepsilon
  \ 
  =
  \ 
  \delta_{n,\tau}
  \,.
\end{align*}
For $t>0$,
Markov's inequality gives
\begin{gather}
  \P\left[
  \norm{\G_n}^*_{\mathcal{F}_{n,\tau}}
   \ge t
  \right]
  \ 
  \le
  \ 
  \frac{1
  }{t}
  \,
    \E\left[
  \norm{\G_n}^*_{\mathcal{F}_{n,\tau}}
    \right]
  \ 
  \le
  \ 
  \frac{1
  }{t}
  \,
    \E^*\left[
  \norm{\G_n}_{\mathcal{F}_{n,\tau}}
    \right]
    \le
    \frac{\delta_{n,\tau}}{t}
    \,,
\end{gather}
and consequently
\begin{gather}
  \P\left[
  \norm{\G_n}^*_{\mathcal{F}_{n,\tau}}
  \le 
  \frac{1}{\tau}
  C_Y
  C_w
  \gamma_\tau
  r_n
  \right]
  \ 
  \ge
  \ 
  1-\tau
\end{gather}
Next, note that
\begin{gather}
  \norm{f_w}_\infty
  \le
  C_Y
  \norm{nw- \frac{1}{\pi(X)}}
  \le
  C_Y
  C_w
  \gamma_\tau
  r_n
\end{gather}
with probability greater than $1-\tau$.
Thus 
$
f_w \in \mathcal{F}_{n,\tau}
$
with probability greater than $1-\tau$.
It follows
\begin{gather}
  \P
  \left[
  \G_n f_w \le 
  \frac{1}{\tau}
  C_Y
  C_w
  \gamma_\tau
  r_n
  \right]
  \ge
  1 - 2\tau
  \,.
\end{gather}
\todo[color=green!40,inline]{Streamline analysis of second term.}
\subsubsection*{3rd term}
We localize with regards to 
$
f_w \in \mathcal{F}_{n,\tau}
.
$
We require the weights to be smalle that 1, such that 
we always have
$
\norm{nw-  \frac{1}{\pi}}
\le
n + \frac{1}{C_\pi}
$.
\begin{gather}
  \E[f_w]
  \le
  C_Y 
  C_w
  \gamma_\tau
  r_n
  (1-\tau)
  +
  C_Y
  (
n + \frac{1}{C_\pi}
  )
  \tau
  \\
  \le
  C_Y
  \left( 
  C_w
  \gamma_\tau
  r_n
  +
  \left(
n + \frac{1}{C_\pi}
  \right)
  \tau
  \right)
  \,.
\end{gather}
If we choose  $\tau=\varepsilon_n$
we get
\begin{gather}
  \E[f_w]
  \le
  C_Y
  \left( 
C_w+1+ \frac{1}{C_\pi}
  \right)
  \varepsilon_n
  \,.
\end{gather}
Selecting the worst instance of learning rate, confidence and uniform constant concludes the proof.

\todo[color=green!40,inline]{Streamline analysis of third term.}
\end{proof}

\begin{reflection*}
  Why did we use empirical process theory instead of conventional concentration inequalities?
  The weights $w$ are random, so $f_w$ is random as well. 

Best is $\gamma_\tau=1$, when we recover the learning rate of the estimator, that is, $(r_n)$.
The confidence $\gamma_\tau/\tau$ is substandard. Improvements may involve Bernstein like concentration for empirical processes (cf. \cite[Section~2.14.2]{vaart2013})
\end{reflection*}
\todo[color=red!40, inline]{Continue section with rates for right outcome model and then both models right. Do the rates improve?}

Next we need to assume that the weights and outcome are independent given treatment and covariates, that is,
\begin{gather}
  Y\!(1)\perp\!\!\!\perp w\ |\ X,T 
  \,.
\end{gather}
Also the bias of the outcome regression has to be bounded by the weights. We get the following error decomposition
\begin{align}
  \frac{1}{n}
  \sum_{i=1}^{n}
  nw_i T_i (Y_i - \E[Y(1)|X_i])
  +
  (\E[Y(1)|X_i]-\E[Y(1)])
  \\
  +
  \sum_{i=1}^{n} 
  (T_i w_i-1/n)
  (
  \E[Y(1)|X_i]
  -
  B(X_i)\lambda
  )
  \\
  +
  \sum_{i=1}^{n} 
  (w_i-1/n)
  B(X_i)\lambda
\end{align}
The expectation of summand in the first term is zero. Hence the convergence by wlln or more refined methods.
The second term goes to 0 by the consistency of the outcome regression.
The third term is bounded by the weights.

\begin{align*}
  \E[
    Tw
    \cdot
    (
      Y\!(T) - \E[Y\!(1)\,|\,X]
      \,
    )
  ]
  \ 
  =
  \ 
  \E
  [
    T
    \cdot
    \E[
    w
    \,
    |
    \,
    T,X
    ]
    \cdot
      \E[Y\!(T)-Y\!(1)\,|\,T,X]
      \,
  ]
  \ 
  =\ 0
\end{align*}
The first equality stems from the conditional independence assumptions. The resulting term vanishes because the difference $Y\!(T)-Y\!(1)$ does so after conditioning on $T=1$.

\begin{align}
  \left| 
  \sum_{i=1}^{n} 
  (T_i w_i-1/n)
  (
  \E[Y(1)|X_i]
  -
  B(X_i)\lambda
  )
  \right|
  \le
  2
  \max_{i=1,\ldots,n}
  \left| 
  \E[Y(1)|X_i]
  -
  B(X_i)\lambda
  \right|
  \\
  \le
  2
  \,
  \text{lerning rate triple of regression}
\end{align}
with probability greater than $1-\tau$.
Note, that 
the weights sum to 1.
Assume 
$
  \left| 
  \sum_{i=1}^{n} 
  (T_i w_i-1/n)
  B_k(X_i)
  \right|
  \le \delta_k
$
for all $k=1,\ldots,K$ and the deltas go to zero with some rate.
The by Cauchy-Schwarz it follows
\begin{gather}
  \left| 
  \sum_{i=1}^{n} 
  (T_i w_i-1/n)
  B(X_i)\cdot \lambda
  \right|
  \le \left| 
  \inner{(\delta_k)}{\lambda}
  \right|
  \le
  \text{rate of deltas}
  \cdot
  \norm{\lambda}
\end{gather}
So we assume $\lambda\in \Theta$, where the parameter space $\Theta$ is compact or grows moderately with $K$.


\todo[color=red!40, inline]{Introduce concept of semiparametric efficiency. For the semiparametric efficiency bound of propensity score weighting, \cite{Hahn1998} is a good reference. General introduction to semiparametric models see \cite[§25]{Vaart2000}.}

\begin{takeaways}
  Each error decomposition furnishes information about the asymptotic properties of the weighted mean. We always get consistency, but learning rates may differ. Obtaining good confidence depends on employing more refined concentration inequalities like Bernstein's inequality. If both treatment and outcome model are well specified we reach the semiparametric efficiency bound of weighting with the true inverse propensity score.
\end{takeaways}

