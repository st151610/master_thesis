%read the paper \cite{Zhao2017a} for discussion of double robustness for balancing weights and \cite{Hahn1998} for semiparametric efficiency bounds.

By double robustness we mean the property of an estimator that it is consistent if either one of treatment or outcome model is well specified.
The augmented weighting estimator was designed to have exactly this property.
Surprisingly, the weighted mean estimator in the balancing weights approach of \cite{Wang2019} retains this feature despite its simplicity \cite{Zhao2017a}. 
In the following we explore double robustness in the weighted mean estimator from the perspective of learning rates.
We will adopt a similar notion of learning rates as in \cite{Steinwart2008}.
To the best of our knowledge this approach is new. Indeed, the existing literature is mostly concerned with consistency and treats learning rates somewhat superficially. 
\subsection{Learning Rates of the weighted mean}

What is the speed of convergence in the weak law of large numbers?
The next statement gives a clear-cut answer:
The arithmetic mean of independent, identically distributed, square-integrable random variables 
learns with rate $n^{-1/2}$.
Furthermore, the statement is easy to prove using
Bienaym√©'s formula and Chebyshev's inequality (cf. \cite[Theorem~5.14]{Klenke2020}).


\begin{theorem*}
  Let 
  $
    X_1,X_2,\ldots
  $
  be i.i.d, square-integrable random variables with 
  $
    V:=
    \mathbf{Var}[X_1]
    <\infty
  $.
  Then, for any $\tau \in (0,1]$ and all $n\in\mathbb{N}$, we have
  \begin{gather}
   \P
   \left[
     \left| 
   \frac{1}{n}
   \sum_{i=1}^{n}
   (X_i - \E[X_i])
     \right|
     \le
     \sqrt{V}
     \frac{1}{\sqrt{\tau}}
     \frac{1}{\sqrt{n}}
   \right]
   \ge
   1-\tau\,.
  \end{gather}
\end{theorem*}
\begin{reflection*}
  Bernsteins's inequality yields better confidence.
\end{reflection*}

\begin{theorem}
  \emph{(Bernstein's inequality)}
  Let
  $
  (\Omega,\mathcal{A},\P)
  $ 
  be a probability space, 
  $
  B>0
  $ 
  and
  $
  \sigma>0
  $
  be real numbers,
  and
  $
  n\ge 1
  $
  be an integer.
  Furthermore, 
  let
  $
  X_1,\ldots,X_n
  :
  \Omega
  \to
  \R
  $
  be independent random variables satisfying
  $
  \E[X_i]=0
  $,
  $
  \norm{X_i}_\infty
  \le
  B
  $
  and
  $
  \E[X_i^2]\le \sigma^2
  $
  for all 
  $
  i=1,\ldots,n
  $.
  Then we have
  \begin{gather*}
    \P
    \left[ 
      \,
      \left| 
      \frac{1}{n}
        \sum_{i=1}^{n} 
        X_i
      \right|
      \ 
      \ge
      \ 
      \sqrt{
        \,
        \frac{2\,\sigma^2 \tau}{n}
        \,
      }
      \ 
      +
      \
      \frac{2 B \tau}{3n}
      \,
    \right]
    \ 
    \le
    \ 
    \exp(1-\tau)
    \,
    ,
    \qquad
    \tau>0\,.
  \end{gather*}
\end{theorem}
\begin{proof}
  Confer \cite[Theorem~6.12]{Steinwart2008}
  for the one-sided version. 
  The two-sided version, as stated in the above theorem, is an easy consequence. We omit the details.
\end{proof}
$
\sqrt{2}(\sigma\lor B)\frac{1}{\sqrt{n}}
\log(e/\tau)
$
\todo[color=green!40, inline]{Improve quality of presentation in order to merge this part with more cultivated sections of the thesis.}
Deriving learning rates in this way, we call for \textit{observed outcomes of the treated}
following the same distribution as
~\textit{
marginal potential outcomes under treatment.}
In other words, we require
\begin{gather}
  Y(1)\,|\,T=1
  \ 
  \sim 
  \ 
  \P_
  {
  Y(1)
  }
  \,.
\end{gather}
In practice, virtually every scenario violates this assumption.
Compare the health of an asthmatic nonsmoker with that of an otherwise healthy smoker.
  Indeed, any unbalanced external influence on both $T$ and $Y(1)$ ruins the 
above assessment, simply by imposing 
\begin{gather}
  \E[Y(T)\,|\, T=1]\ \neq\  \E[Y(1)]
  \,.
\end{gather}
We speak of a \textbf{confounded} scenario, that is, the unbalanced external influence is called a \textbf{confounder}. Having asthma  is a confounder when regarding the health risks of smoking.



\begin{ftheorem}
  \emph{(Work in progress)}
Let us take a moment to understand the meaning of the word.
The verb \textit{to confound} has nuances of meaning\cite{zotero-327}

to throw (a person) into confusion

in this case the Statistician or whoever wishes to inform his decisions on the basis of data.

refute

A change of effect when stratifying is a strong refutation.

to put to shame

To embarrass some on who used invalid analysis as an argument in a  public debate. 

damn



to fail to discern differences between : mix up

Maybe in the sense of conflate: see causal effects where there are non.

to increase the confusion of

after a change of effect. what should be trusted?

baffle, frustrate

yield to this and stop asking causal questions.



archaic : to bring to ruin

ruin the analysis, assesment.

 obsolete : consume, waste 

 waste the effort of conducting the analysis.



\end{ftheorem}

The presence of confounders, especially when overlooked, is so mystifying that the statistical literature coins the term \textit{Simpson's paradox} to relate to the issue of confounding (cf.\cite{Wagner1982} for a brief discussion of Simpson's paradox and some real world examples).
\todo[color=orange!40,inline]{What solutions were offerd to deal with confounding? Start from propensity scores.}
Statisticians have wrestled with this issue for nearly a century.

In experimental studies we usually specify treatment assignment as opposed to merely observing a unit receiving treatment. 

The next statement makes use of the propensity score.

\begin{theorem*}
  Consider the weighted mean estimator with weights
  \begin{gather}
    w_i
    \ 
    =
    \ 
    \frac{1}{n}
    \frac{T_i}{\pi(X_i)}
    \,.
  \end{gather}
  Denote
  $
    V:=
    \E[
    (
      Y(1)
    )^2
    \,/\,
    \pi(X)
    ]
    -
    \E[Y(1)]^2
  $.  
  Assume that \textit{weak unconfoundedness} holds.
  Then, for any $\tau \in (0,1]$ and all $n\in\mathbb{N}$, we have
  \begin{gather}
   \P
   \left[
     \,
     \left| 
     \,
   \sum_{i=1}^{n}
   w_iY_i - \E[Y(1)]
   \,
     \right|
     \ 
     \le
     \ 
     \sqrt{V}
     \frac{1}{\sqrt{\tau}}
     \frac{1}{\sqrt{n}}
     \,
   \right]
   \ 
   \ge
   \ 
   1-\tau\,.
  \end{gather}

\end{theorem*}
\begin{proof}
We want to reinforce coherent use of the weak law of large numbers.
To this end, we verify 
\begin{align*}
  n\,\E[w(T,X)\,Y(T)]
  \ 
  &=
  \ 
  \E[Y(1)]
  \,,
  \\
  n^2\,
  \mathbf{Var}[w(T,X)\,Y(T)]
  \ 
  &=
  \ 
    \E[
    (
      Y(1)
    )^2
    \,/\,
    \pi(X)
    ]
    -
    \E[Y(1)]^2
    \,.
\end{align*}
Essentially, the random weight $w(T,X)$ acts on $Y(T)$ through $T\,/\,\pi(X)$.
It does so by inducing independence of observed outcome $Y(T)$ and treatment $T$.
This requires that weak unconfoundedness holds, i.e., 
\begin{gather}
  (Y(0),Y(1))\perp\!\!\!\perp T\, |\, X\,.
\end{gather}
To showcase the details we added an $n$ and $n^2$ factor in the above display.
The calculations go as follows.
\begin{align}
  \begin{split}
  n\,\E[w(T,X)\,Y(T)]
  &\ 
  =
  \ 
  \E
  \left[ 
    Y(T)
    \cdot
    (T\,/\,\pi(X))
  \right]
  \\
  &\ =\ 
  \E
  \left[ 
    Y(1)
    \,
    /
    \,
    \pi(X)
    \,
    \vert
    \,
    T=1
  \right]
  \cdot
  \P[T=1]
  \\
  &\ =\ 
  \int_\mathcal{X}
  \E
  \left[ 
    Y(1)
    \,
    \vert
    \,
    X=x
    ,
    T=1
  \right]
  \cdot
  (
  \P[T=1]
  \,
  /
  \,
  \pi(x)
  )
  \,
  \P_{X|T}(dx\,|\,1)
  \\
  &\ =\ 
  \int_\mathcal{X}
  \left[ 
    Y(1)
    \vert
    X=x
  \right]
  \P_X(dx)
  =
  \E[Y(1)]
  .
\end{split}
\end{align}
The first equality holds because of the definition of the weights.
The second, third and last equality stem from 
$
  T\in \left\{ 0,1 \right\}
$,
and the law of total expectation, applied with $T$ and $X$.
The fourth equality is justified by the assumption of weak unconfoundedness.
The density transformation is due to Bayes's Theorem.
With slight modifications in the above argument, it follows
\begin{gather}
  \E
  \left[ 
  \Big( 
    Y(T)
    \cdot
    (T\,/\,\pi(X))
  \Big)
  ^2
  \right]
  \ 
    =
    \ 
    \E
    \Big[
    (Y(1))^2
    \,
    /
    \,
    \pi(X)
    \Big]
    \,.
\end{gather}
We omit the details.
Invoking the weak law of large numbers finishes the proof.
\end{proof}
\todo[color=orange!40,inline]{Formulate improved version with Bernstein.}

\todo[color=orange!40,inline]{Formulate better transition to weights with estimated propensity score.}
We started by asking an easy question, so it is time for a more challenging one: How do we proceed in deriving learning rates if the propensity score is unknown.
How do we generally procede?
[what has been done in the past. Why are some methods obsolete]
A naive answer would be: We hope to select a proper model and try to estimate the propensity score.
Stunningly, a lot of practicioners still settle for obsolete methods when it comes to propensity score analysis.


Next, we consider the event that we have a consistent estimator of the 
propensity score and the distribution of the covariate vector $X$, 
along with that of the outcome $Y$, 
has compact support.
The next assumptions reduce the technical task to a minimum.

\begin{assumptions*}
  Let the following hold.
  \begin{enumerate}[label={(\roman*)}]
    \item
      There exists $C_Y\ge 1$ such that $|Y(1)|\le C_Y$ almost surely. 
    \item
      There exists $C_\pi > 0$ such that $C_\pi < \pi(X)$ almost surely.
    \item
      There exists a function class $\mathcal{F}$ 
      with unit ball 
      $
        B_\mathcal{F}
        :=
        \left\{ 
          f\in \mathcal{F}
          \colon
          \norm{f}_\infty
          \le 
          1
        \right\}
      $
      such that  
      $
          \log N_{[\,]}(\varepsilon, B_\mathcal{F}, L_2(\P))
        \le
        C_{\mathcal{F}}
        (1/\varepsilon)^{1/k} 
      $
      for some $k>1/2$ and some constant $C_\mathcal{F}\ge 1$.
    \item
      The random function $f_w$ defined by
      $
  f_w(T,X,Y)
  \ 
  :=
  \ 
  \left( 
   n\, w(X)
    \ 
    -
    \ 
    \frac{1}{\pi(X)}
  \right)
  \,
  T
  \,
  Y
      $
      satisfies
      $f_w\in \mathcal{F}$
      almost surely
      .
  \item 
    There exist a learning rate 
    $
    (r_n)
    $,
    confidence constants
    $
    (\gamma_\tau)
    $
    and 
    uniform constant
    $
    C_w\ge 1
    $
    such that
    for all $\tau \in(0,1]$
    and all $n \in \mathbb{N}$
    it holds
    $
    \P
    \left[ 
    \norm{w(X) - \frac{1}{\pi(X)}}_\infty
    \le
    C_w
    c_\tau
    \varepsilon_n
    \right]
    \ge 
    1-\tau
    $
    \item
      There exists $\alpha > 1$ 
  such that 
  $
  \varepsilon_n \cdot c_{n^{-\alpha}}
  \to 
  0
  $
  as 
  $
  n\to \infty
  $
  and 
  $
  \varepsilon_n \cdot c_{n^{-\alpha}}
  \le 
  1
  $
  for all 
  $n \in \mathbb{N}$.
  \end{enumerate}
\end{assumptions*}
\todo[color=orange!40, inline]{Elaborate on assumptions. For example (iii) \cite[¬ß2.7.1]{vaart2013}
  \cite[¬ß19.9]{Vaart2000}
}
\begin{theorem*}
  Let the assumptions.
  Then the weighted mean learns with rate
  $
    (\varepsilon_n)
  $
  defined by
  \begin{gather*}
    \varepsilon_n
    \ 
    :=
    \ 
    \inf
    \left\{ \,t \,\in\,  (\,0,1]
      \ 
      \colon
      \ 
  r_n \cdot \gamma_{\,t/n}
  \ 
  \le
  \ 
  t
  \,
    \right\}
    \ 
    \land 
    \ 
    1
    \qquad
    \text{for all}
    \ 
    n\in \mathbb{N}
    \,.
  \end{gather*}
  Furthermore, it has confidence constants
  $
  (c_\tau)
  $
  given by
\begin{gather}
  c_\tau = \gamma_\tau /\tau
\end{gather}
  and uniform constant
  \begin{gather}
C_\P    
=
\max
\left\{ 
  \sqrt{C_\mathcal{F}}
  C_w
  ,
  C_Y
  C_w
  ,
  \frac{C_Y}{C_\pi}
\right\}
  \end{gather}
\end{theorem*}

\begin{proof}
  We consider the following error decomposition.
\begin{align}
  \begin{split}
  &\sum_{i=1}^{n}
  \,
  w_i\,T_i\,Y_i
  \ 
  -
  \ 
  \E[Y(1)]
  \\
  &\quad=
    \ 
    \frac{1}{n}
    \,
  \sum_{i=1}^{n}
  \,
    \frac{T_i}{\pi(X_i)}
    \,
  \left(
    \,
    Y_i
    \ 
    -
    \ 
  \E[Y(1)]
  \,
  \right)
  \ +
  \ 
  \sum_{i=1}^{n}
  \,
  \left( 
    w_i
    \ 
    -
    \ 
    \frac{1}{n}\,
    \frac{1}{\pi(X_i)}
  \right)
  \,
  T_i
  \,
  Y_i
  \,.
  \\
  & 
  \quad
  =
  \ 
   \frac{1}{n}
    \,
  \sum_{i=1}^{n}
  \,
    \frac{T_i}{\pi(X_i)}
    \,
  \left(
    \,
    Y_i
    \ 
    -
    \ 
  \E[Y(1)]
  \,
  \right)
  \ 
  +
  \ 
  \frac{1}{\sqrt{n}}
  \,
  \G_n f_w
  \ 
  -
  \ 
  \E[
  \,
  f_w(T,X,Y)
  \,
  ]
  \,.
  \end{split}
\end{align}
We already bounded the first term. 
To bound the remaining terms we will use the learning rates of $w$.
To this end, we employ maximal inequalities for empirical processes to bound the second term.
We bound the third term by the law of total expectation and balancing learning rates and confidence.
\subsubsection*{2nd term}
Denote
$
  \mathcal{F}_{n,\tau}
  :=
  (
  C_Y
  C_w
  \gamma_\tau
  r_n
  )
  \cdot
  B_\mathcal{F}
  =:
  \delta_{n,\tau}
  \cdot
  B_\mathcal{F}
$.
It holds by maximal inequalities
\begin{align*}
  \E^*\left[ 
    \norm{\G_n}_{\mathcal{F}_{n,\tau}}
  \right]
  &
  \ 
  \le
  \ 
  \int_0^{\delta{n,\tau}}
  \sqrt{
    \log 
    N_{[\,]}
    \left( 
      \varepsilon / \delta_{n,\tau}
    ,
    B_{\mathcal{F}}
    ,
    L_2(\P)
    \right)
  }
  d\varepsilon
  \\
  &
  \ 
  \le
  \ 
  \int_0^{\delta_{n,\tau}}
  \left( 
    \frac{\delta_{n,\tau}}{\varepsilon}
  \right)^{1/(2k)}
  d \varepsilon
  \ 
  =
  \ 
  \delta_{n,\tau}
  \,.
\end{align*}
For $t>0$,
Markov's inequality gives
\begin{gather}
  \P\left[
  \norm{\G_n}^*_{\mathcal{F}_{n,\tau}}
   \ge t
  \right]
  \ 
  \le
  \ 
  \frac{1
  }{t}
  \,
    \E\left[
  \norm{\G_n}^*_{\mathcal{F}_{n,\tau}}
    \right]
  \ 
  \le
  \ 
  \frac{1
  }{t}
  \,
    \E^*\left[
  \norm{\G_n}_{\mathcal{F}_{n,\tau}}
    \right]
    \le
    \frac{\delta_{n,\tau}}{t}
    \,,
\end{gather}
and consequently
\begin{gather}
  \P\left[
  \norm{\G_n}^*_{\mathcal{F}_{n,\tau}}
  \le 
  \frac{1}{\tau}
  C_Y
  C_w
  \gamma_\tau
  r_n
  \right]
  \ 
  \ge
  \ 
  1-\tau
\end{gather}
Next, note that
\begin{gather}
  \norm{f_w}_\infty
  \le
  C_Y
  \norm{nw- \frac{1}{\pi(X)}}
  \le
  C_Y
  C_w
  \gamma_\tau
  r_n
\end{gather}
with probability greater than $1-\tau$.
Thus 
$
f_w \in \mathcal{F}_{n,\tau}
$
with probability greater than $1-\tau$.
It follows
\begin{gather}
  \P
  \left[
  \G_n f_w \le 
  \frac{1}{\tau}
  C_Y
  C_w
  \gamma_\tau
  r_n
  \right]
  \ge
  1 - 2\tau
  \,.
\end{gather}
\todo[color=green!40,inline]{Streamline analysis of second term.}
\subsubsection*{3rd term}
We localize with regards to 
$
f_w \in \mathcal{F}_{n,\tau}
.
$
We require the weights to be smalle that 1, such that 
we always have
$
\norm{nw-  \frac{1}{\pi}}
\le
n + \frac{1}{C_\pi}
$.
\begin{gather}
  \E[f_w]
  \le
  C_Y 
  C_w
  \gamma_\tau
  r_n
  (1-\tau)
  +
  C_Y
  (
n + \frac{1}{C_\pi}
  )
  \tau
  \\
  \le
  C_Y
  \left( 
  C_w
  \gamma_\tau
  r_n
  +
  \left(
n + \frac{1}{C_\pi}
  \right)
  \tau
  \right)
  \,.
\end{gather}
If we choose  $\tau=\varepsilon_n$
we get
\begin{gather}
  \E[f_w]
  \le
  C_Y
  \left( 
C_w+1+ \frac{1}{C_\pi}
  \right)
  \varepsilon_n
  \,.
\end{gather}
Selecting the worst instance of learning rate, confidence and uniform constant concludes the proof.

\todo[color=green!40,inline]{Streamline analysis of third term.}
\end{proof}

\begin{reflection*}
  Why did we use empirical process theory instead of conventional concentration inequalities?
  The weights $w$ are random, so $f_w$ is random as well. 


Best is $\gamma_\tau=1$, when we recover the learning rate of the estimator, that is, $(r_n)$.
The confidence $\gamma_\tau/\tau$ is substandard. Improvements may involve Bernstein like concentration for empirical processes (cf. \cite[Section~2.14.2]{vaart2013})
\end{reflection*}
\todo[color=red!40, inline]{Continue section with rates for right outcome model and then both models right. Do the rates improve?}

Next we need to assume that the weights and outcome are independent given treatment and covariates.
Also the bias of the outcome regression has to be bounded in terms of the weights. We get the following error decomposition
\begin{align}
  \frac{1}{n}
  \sum_{i=1}^{n}
  nw_i T_i (Y_i - \E[Y(1)|X_i])
  +
  (\E[Y(1)|X_i]-\E[Y(1)])
  \\
  +
  \sum_{i=1}^{n} 
  (w_i-1/n)
  (
  \E[Y(1)|X_i]
  -
  B(X_i)\lambda
  )
  \\
  +
  \sum_{i=1}^{n} 
  (w_i-1/n)
  B(X_i)\lambda
\end{align}
The expectation of summand in the first term is zero. Hence the convergence by wlln or more refined methods.
The second term goes to 0 by the consistency of the outcome regression.
The third term is bounded in terms of the weights.

\begin{align*}
  &\E[
  \,
    T\, w
    \cdot
    (
    \,
      Y(T)\  -\  \E[\,Y(1)\,|\,X\,]
      \,
    )
  ]
  \\
  &
  \quad 
  =
  \ 
  \E
  [
  \,
    T
    \cdot
    \E[
    \,
    w
    \,
    |
    \,
    T,X
    \,
    ]
    \cdot
    (
    \,
      \E[\,Y(T)\,|\,T,X\,]
      \ 
      -
      \ 
      \E[\,Y(1)\,|\,T,X\,]
      \,
    )
  ]
  \\
  &
  \quad 
  =
  \ 
  \E
  [
  \,
    \E[
    \,
    w
    \,
    |
    \,
    T=1,X
    \,
    ]
    \cdot
    (
    \,
      \E[\,Y(1)\,|\,T=1,X\,]
      \ 
      -
      \ 
      \E[\,Y(1)\,|\,T=1,X\,]
      \,
    )
    \,
    |\,T=1
    \,
  ]
  \\
  &\qquad
  \ 
  \cdot
  \P[\,T=1\,]
  \\
  &\quad
  =\ 0
\end{align*}
