Let $X$ be a $d$-dimensional random variable from which we sample
$N\in\mathbb{N}$ independent and identically distributed copies
$X_1,\ldots,X_N$. Furthermore, let $T\in \left\{ 0,1 \right\}$ 
denote the indicator of treatment and let $T_1,\ldots,T_N$ be i.i.d. 
copies.
Let $Y\in[-M,M]$ be a real-valued bounded random variable with 
$M\in\R$.
We call $X$ the covariate vector, $T$ the indicator of treatment
and $Y$ the outcome.
Before we begin the analysis we order the i.i.d. copies, such that
the first $n$ units received treatment and the remaining $N-n$ units 
are in the control group.

We want know more about the (potential) outcome under treatment 
in the population.
But we observe the outcome $Y$ depending on $T$,
that is
\begin{gather}
  Y_i \sim Y|T_i
  \,.
\end{gather}
In the presence of confounders we have
\begin{gather}
  Y|T=1 \nsim Y(1)
  \,.
\end{gather}
We want to create weights
$w_1,\ldots,w_n$ for the treated, such that for large $n$ we get
\begin{gather}
  w_i \cdot Y_i \sim Y(1)
  \,.
\end{gather}
We extend ideas from entropy balancing weights~\cite{Wang2019}.

To be precise in our statements, we introduce some notation.
\subsection*{Basis Functions}
We consider a partition
$
  \mathcal{P}_N
  =
  \left\{ 
    A_{N,1}
    ,
    A_{N,2}
    ,
    \ldots
  \right\}
$
of $ \R^d $
and define
$ A_N(x) $ to be the cell of $ \mathcal{P}_N $ containing $x$.
We define $N$ basis functions $B_k$ of the covariates by
\begin{gather*}
  B_k(x)
  :=
  \frac{
  \mathbf{1}_{X_k \in A_N(x)}
  }{
  \sum_{j=1}^{N} 
  \mathbf{1}_{X_j \in A_N(x)}
  }
  \,,
  \qquad
  k=
  1,\ldots,N
  \,.
\end{gather*}
The euclidian norm of the basis functions is bounded above by $1$.
\begin{gather*}
  \norm{B(x)}^2
  =
  \sum_{k=1}^{n} 
  \left( 
  \frac{
  \mathbf{1}_{X_k \in A_n(x)}
  }{
  \sum_{j=1}^{n} 
  \mathbf{1}_{X_j \in A_n(x)}
  }
  \right)
  ^2
  \le
  \sum_{k=1}^{n} 
  \frac{
  \mathbf{1}_{X_k \in A_n(x)}
  }{
  \sum_{j=1}^{n} 
  \mathbf{1}_{X_j \in A_n(x)}
  }
  =1
  \,.
\end{gather*}
Under mild conditions, the basis functions are universally consistent.
\begin{theorem}
  If for each sphere $S$ centered at the origin 
  \begin{gather}
    \max
    _
    {
      j\colon
      A_{N,j} 
      \cap
      S
      \neq
      \emptyset
    }
    \mathrm{diam}
    \ 
      A_{N,j} 
      \ 
      \to
      \ 
      0
      \qquad
      \text{for}\ 
      N\to \infty 
  \end{gather}
  and
  \begin{gather}
    \frac
    {
    \#
    \left\{  
      j\colon
      A_{N,j} 
      \cap
      S
      \neq
      \emptyset
    \right\}
    }
    {N}
      \ 
      \to
      \ 
      0
      \qquad
      \text{for}\ 
      N\to \infty 
  \end{gather}
  then the partitioning regression function estimate 
  (definition)
  is
  universally consistent (definition).
\end{theorem}

\subsection*{Convex Optimization}

We now consider the convex optimization problem for the weights.
We assume the objective function $f$ to be strictly convex, such that its convex conjugate is continuously differentiable. Furthermore we 
assume the bound on the box-constraints $\delta>0$ to converge to $0$ in probability. 
\begin{fproblem}
  \label{bw:1:primal}
\begin{align*}
  %%%% objective %%%%
    &\underset{w_1, \ldots, w_n \in \R}
    {\text{minimize}}
    &&\qquad\qquad
    \sum_{i = 1}^{n} 
    f(w_i)
    &&&
    \\
    %%%% w_i T_i >= 0 %%%%
    &\text{subject to}
    &&\qquad\qquad
    w_i 
    \ge
    0
    &&&
    \qquad
    \text{for all}\ 
    i \in \left\{ 1, \ldots, n \right\}
    \,,
    \\
    %%%% 1/n sum w = 1 %%%%
    & 
    &&\qquad\qquad
    \frac{1}{N}
    \sum_{i=1}^{n} 
    w_i
    =1
    \\
    %%%% box constraints %%%%
    & 
    &&\qquad
    \left| 
      \frac{1}{N} 
      \left( 
      \sum_{i = 1}^{n} 
      w_i
      B_k(X_i)
      -
      \sum_{i=1}^{N} 
      B_k(X_i)
      \right)
    \right|
    \ 
    \le 
    \ 
    \delta_k
    &&&
    \qquad
    \text{for all}\ 
    k \in \left\{ 1, \ldots, N \right\}
    \,.
\end{align*}
\end{fproblem}
To obtain consistency for the weights we will analyse the dual.

