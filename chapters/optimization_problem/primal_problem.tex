Let
$\overline{\R}:=\R\cup \left\{ \infty \right\}$ 
be the extended real numbers
and let $\mathcal{B}(\R)$ denote the Borel-$\sigma$-algebra on the real numbers.

For a 
\begin{align*}
  \text{
(proper) convex function
  }
  \qquad
  \varphi\ \colon\  \R\ \to\ \overline{\R}
\end{align*}
a vector of $N$ (basis-)functions of the covariates 
\begin{gather*}
  B
  \ 
  :=
  \ 
  \left[ 
    B_1,\ldots,B_N
  \right]^\top
  \qquad
  \text{with}\qquad 
  B_k\ \colon\  \R^d\ \to\ \R
  \qquad
  \text{for all}\ k\in \left\{ 1,\ldots,N \right\}
  \,,
\end{gather*}
and a (random) constraints vector
\begin{align*}
\delta=[\delta_1,\ldots,\delta_N]^\top
\qquad
  \text{with}\qquad 
  \delta_k\ \colon\  (\Omega,\sigma(D_N),\P)\ \to\ \R
  \qquad
  \text{for all}\ k\in \left\{ 1,\ldots,N \right\}
  \,,
\end{align*}
we consider the following (random) convex optimization problem.
\newpage
\begin{fproblem}
  \label{bw:1:primal}
\begin{align*}
  %%%% objective %%%%
    &\underset{w_1, \ldots, w_n \in \R}
    {\text{minimize}}
    &&\qquad\qquad
    \sum_{i = 1}^{n} 
    \varphi(w_i)
    &&&
    \\
    %%%% w_i T_i >= 0 %%%%
    &\text{subject to}
    &&\qquad\qquad
    w_i 
    \ge
    0
    &&&
    \qquad
    \text{for all}\ 
    i \in \left\{ 1, \ldots, n \right\}
    \,,
    \\
    %%%% 1/n sum w = 1 %%%%
    & 
    &&\qquad\qquad
    \frac{1}{N}
    \sum_{i=1}^{n} 
    w_i
    =1
    \\
    %%%% box constraints %%%%
    & 
    &&\qquad
    \left| 
      \frac{1}{N} 
      \left( 
      \sum_{i = 1}^{n} 
      w_i
      B_k(X_i)
      -
      \sum_{i=1}^{N} 
      B_k(X_i)
      \right)
    \right|
    \ 
    \le 
    \ 
    \delta_k
    &&&
    \qquad
    \text{for all}\ 
    k \in \left\{ 1, \ldots, \# \mathfrak{B} \right\}
    \,.
\end{align*}
\end{fproblem}
What is random in Problem~\ref{bw:1:primal}?
First, the dimension of the search space $(w\in\R^n)$ depends on the random variable $n$. 
Thus, we only compute weights for the treated units (the ones with $T_i=1$).
Next consider the \textbf{objective function}
\begin{gather*}
    \sum_{i = 1}^{n} 
    \varphi(w_i)
    \,.
\end{gather*}
The number of summands is random (again $n$). We sometimes use the equivalent notation
\begin{gather*}
    \sum_{i = 1}^{N} 
    T_i
    \cdot
    \varphi(w_i)
    \,,
\end{gather*}
where we set the weights of the untreated (the ones with $T_i=0$) to some arbitrary value in the domain of $\varphi$.
Let's consider the constraints. There is no randomness in the first two constraints.
\begin{gather*}
    w_i 
    \ge
    0
    \qquad
    \text{for all}\ 
    i \in \left\{ 1, \ldots, n \right\}
    \quad
    \text{and}
    \quad
    \frac{1}{N}
    \sum_{i=1}^{n} 
    w_i
    =1
    \,.
\end{gather*}
They only make sure, that the weights (divided by $N$) form a convex combination.
If, for example, the outcome space $\mathcal{Y}$ is convex we make sure that a weighted-mean-estimate of $\E[Y(1)]$ satisfies
\begin{gather*}
  \widehat{Y}(1) 
  \ 
  :=
  \ 
  \frac{1}{N}
  \sum_{i=1}^{n} 
  w_i\cdot Y_i
  \ 
  \in
  \ 
  \mathcal{Y}
\end{gather*}
or that a weighted-mean-estimate of the distribution function of $Y(1)$ satisfies
\begin{gather*}
  \widehat{F}_{Y(1)} 
  \ 
  :=
  \ 
  \frac{1}{N}
  \sum_{i=1}^{n} 
  w_i\cdot \mathbf{1}\left\{ Y_i\le z \right\}
  \ 
  \in
  \ 
  [0,1]
  \,.
\end{gather*}
There remain the box constraints
\begin{gather*}
    \left| 
      \frac{1}{N} 
      \left( 
      \sum_{i = 1}^{n} 
      w_i
      B_k(X_i)
      -
      \sum_{i=1}^{N} 
      B_k(X_i)
      \right)
    \right|
    \ 
    \le 
    \ 
    \delta_k
    \qquad
    \text{for all}\ 
    k \in \left\{ 1, \ldots, \# \mathfrak{B} \right\}
    \,.
\end{gather*}
Here the number of summands in
\begin{gather*}
      \sum_{i = 1}^{n} 
      w_i
      B_k(X_i)
\end{gather*}
is again random, and we sometimes use the equivalent notation
\begin{gather*}
      \sum_{i = 1}^{N} 
      T_i
      \cdot
      w_i
      \cdot
      B_k(X_i)
      \,.
\end{gather*}
The (basis-)functions in $\mathfrak{B}$ can be random functions, for example, if they depend on the data $D_N$.
Also the constraint vector $\delta$ can depend on the data (see \cite[Algorithm~1 on page 11]{Wang2019}).
