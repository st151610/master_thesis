We consider a set of (measurable) basis functions 
\begin{gather*}
  \mathfrak{B}
  :
  =
  \left\{ 
B_k\colon (\mathcal{X},\Sigma_\mathcal{X})\to(\R,\mathcal{B}(\R))
\ 
|
\ 
k\in \left\{ 1,\ldots,\# \mathfrak{B} \right\}
  \right\}
  \,,
\end{gather*}
and write
\begin{gather*}
  B(x)
  :=
  [B_1(x),\ldots,B_{\# \mathfrak{B}}(x)]^\top
  \,.
\end{gather*}
\begin{assumption}
  \label{asu:basis}
  The set of (measurable) basis functions 
  $
  \mathfrak{B}
  $
  satisfies
  \begin{itemize}
    \item
      $\norm{B(x)}_2\lesssim 1$ for all $x\in \mathcal{X}$.
    \item
      For all continuous functions $f\colon \R^d\to \R$ there exists a random vector
      $\lambda^*_{f}\in\R^{\#\mathfrak{B}}$ such that
      for all $i\in \left\{ 1,\ldots, N \right\}$ it holds
      \begin{gather*}
        \left| 
        \inner{B(X_i)}{\lambda^*_f}
        -
        f(X_i)
        \right|
        \to 
        0
        \qquad
        \text{for}
        \ 
        N\to\infty
        \,.
      \end{gather*}
  \end{itemize}
\end{assumption}

Next, we give some examples. 
We begin with a histogram basis \cite[ยง4]{Gyorfi2002}
\begin{example}
We consider a sequence of partitions
$
\left( 
  \mathcal{P}_N
  =
  \left\{ 
    A_{N,1}
    ,
    A_{N,2}
    ,
    \ldots
  \right\}
\right)
$
of $ \R^d $
and define
$ A_N(x) $ to be the cell of $ \mathcal{P}_N $ containing $x$.
We also assume
uniform partition width that decreases to 0, that is,
\begin{gather}
  \label{8881}
  \text{
for all $j\in\mathbb{N}$
it holds
  }
  \qquad
  \lambda^d(A_{N,j})
  \ 
  =
  \ 
  h_N^d
  \ 
  \to
  \ 
  0
  \qquad
  \text{for}
  \ 
  N\to\infty
  \,.
\end{gather}
We define $N$ basis functions $B_k$ of the covariates by
\begin{gather*}
  B_k(x)
  \ 
  :=
  \ 
  \frac{
  \mathbf{1}{\left\{ X_k \in A_N(x) \right\}}
  }{
  \sum_{j=1}^{N} 
  \mathbf{1}{\left\{ X_j \in A_N(x) \right\}}
  }
  \qquad
  \text{for}
  \,
  k\in
  \left\{ 
  1,\ldots,N
  \right\}
  \,,
\end{gather*}
where we keep to the convention $"0/0=0"$.
If at least one $B_k(x)>0$, the basis functions sum to 1. If $B_k(x)=0$ for all basis functions, the sum is 0.
Thus
\begin{align}
  \label{8882}
  \sum_{k=1}^{N}
  B_k(x)
  &
  \ 
  \in
  \ 
  \left\{ 0,1 \right\}
  \qquad
  \text{for all}
  \ 
  x\in\R^d
  \,.
  \notag
  \intertext{
Since $B_i(X_i)>0$, it holds
  }
  \sum_{k=1}^{N}
  B_k(X_i)
  &
  \ 
  =
 \  
  1
  \qquad
  \text{for all}\ 
  i\in
  \left\{ 1,\ldots,N \right\}
  \,.
\end{align}
We check the first condition of Assumption~\ref{asu:basis}. 
Since 
\begin{gather*}
B_k(x)
\ 
\in
\ 
[0,1]
\qquad
\text{for all}\ 
x\in\R^d
\ 
\text{and for all}\ 
k\in \left\{ 1,\ldots,N \right\}
\,,
\end{gather*}
it holds
\begin{gather*}
  \label{basis_l2_bdd}
  \norm{B(x)}_2^2
  \ 
  =
  \ 
  \sum_{k=1}^{N} 
  B_k(x)
  ^2
  \ 
  \le
  \ 
  \sum_{k=1}^{N} 
  B_k(x)
  \ 
  \in
  \ 
  \left\{ 0,1 \right\}
  \quad
  \text{
    for all
  }
x\in\R^d
\,
\,.
\end{gather*}
To verify the second condition of Assumption~\ref{asu:basis} 
let
$f$ be a continuous function
and consider
\begin{gather*}
  \lambda^*_f
  \ 
  :=
  \ 
  [f(X_1),\ldots,f(X_N)]^\top
  \,.
\end{gather*}
Since $f$ is continuous and the $X_k$ are random vectors,
$\lambda^*_f$ is also a random vector.
It follows 
\begin{align*}
  &
        \left| 
        \inner{B(X_i)}{\lambda^*_f}
        -
        f(X_i)
        \right|
        \\
  &
  \ 
        =
  \ 
        \left| 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        f(X_k)
        -
        f(X_i)
        \right|
        \ 
        =
        \ 
        \left| 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        \left( 
        f(X_k)
        -
        f(X_i)
        \right)
        \right|
\\
  &
  \ 
        =
  \ 
        \left| 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        \mathbf{1}
        \left\{ X_k\in A_N(X_i) \right\}
        \cdot
        \left( 
        f(X_k)
        -
        f(X_i)
        \right)
        \right|
        \\
  &
  \ 
        \le
  \ 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        \omega
        ( 
        f,
        \lambda^d(A_N(X_i))
        )
        \\
  &
  \ 
        =
  \ 
        \omega
        ( 
        f,
        h_N^d
        )
        \to
        0
        \qquad
        \text{for}
        \ 
        N\to\infty
        \,,
\end{align*}
where $\omega$ is the modulus of continuity.
The second equality is due to \eqref{8881}, the third equality follows from the definition of the basis functions, and 
the inequality follows from \eqref{8881}, the convexity of the absolute value and the continuity of $f$.
The convergence in due to \eqref{8882}.
\end{example}

We continue with kernel bases \cite[ยง5]{Gyorfi2002}.
\begin{example}
Let
$
  K
  \colon
  \R^d
  \to
  [0,\infty)
$
be a measurable function with $K(0)>0$. 
We call $K$ a kernel function.
We assume that there exists
$R>0$ such that 
\begin{gather}
  \label{8884}
  K(x)
  \ 
  \le
  \ 
  \mathbf{1}\left\{ \norm{x}_2\le R\right\}
  \,,
\end{gather}
that is, the kernel function has compact support.
For a decreasing sequence (the bandwith of the kernel) $(h_N)\in (0,\infty)$ with $h_N\to 0$ for $N\to\infty$,
we define $N$ basis functions $B_k$ of the covariates by
\begin{gather*}
  B_k(x)
  \ 
  :=
  \ 
  \frac{
    K \left( \frac{\norm{x-X_k}_2}{h_N} \right)
  }{
  \sum_{j=1}^{N} 
    K \left( \frac{\norm{x-X_j}_2}{h_N} \right)
  }
  \qquad
  \text{for}
  \,
  k\in
  \left\{ 
  1,\ldots,N
  \right\}
  \,,
\end{gather*}
where (again) we keep to the convention $"0/0=0"$.
Since $K(0)>0$, as in the previous example, it follows
\begin{align}
  \label{8883}
  \sum_{k=1}^{N}
  B_k(x)
  &
  \ 
  \in
  \ 
  \left\{ 0,1 \right\}
  \qquad
  \text{for all}
  \ 
  x\in\R^d
  \,,
  \notag
  \\
  \sum_{k=1}^{N}
  B_k(X_i)
  &
  \ 
  =
 \  
  1
  \qquad
  \text{for all}\ 
  i\in
  \left\{ 1,\ldots,N \right\}
  \intertext{and}
  \notag
  \norm{B(x)}_2^2
  &
  \ 
  \in
  \ 
  \left\{ 0,1 \right\}
  \qquad
  \text{for all}
  \ 
  x\in\R^d
  \,.
\end{align}
This verifies the first condition of Assumption~\ref{asu:basis}.
To verify the second condition, note, that
\begin{align}
  \label{8885}
  \notag
  K(x)
  &
  \ 
  =
  \ 
  \mathbf{1}\left\{ \norm{x}_2\le R \right\} 
  K(x)
  \qquad
  \text{for all}
  \ 
  x\in\R^d
  \intertext{and thus}
  B_k(x)
  &
  \ 
  =
  \ 
  B_k(x)
  \cdot
  \mathbf{1}\left\{ \norm{x-X_k}_2\le R\cdot h_N \right\} 
  \qquad
  \text{for all}
  \ 
  x\in\R^d
  \ 
  \text{and for all}
  \ 
  k\in \left\{ 1,\ldots,N \right\}
  \,.
\end{align}
Let 
$f$ be a continuous function
and consider (as in the previous example)
\begin{gather*}
  \lambda^*_f
  \ 
  :=
  \ 
  [f(X_1),\ldots,f(X_N)]^\top
  \,.
\end{gather*}
It follows
\begin{align*}
  &
        \left| 
        \inner{B(X_i)}{\lambda^*_f}
        -
        f(X_i)
        \right|
        \\
  &
  \ 
        =
  \ 
        \left| 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        f(X_k)
        -
        f(X_i)
        \right|
        \ 
        =
        \ 
        \left| 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        \left( 
        f(X_k)
        -
        f(X_i)
        \right)
        \right|
\\
  &
  \ 
        =
  \ 
        \left| 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
  \mathbf{1}\left\{ \norm{x-X_k}_2\le R\cdot h_N \right\} 
        \cdot
        \left( 
        f(X_k)
        -
        f(X_i)
        \right)
        \right|
        \\
  &
  \ 
        \le
  \ 
        \sum_{k=1}^{N} 
        B_k(X_i)
        \cdot
        \omega
        ( 
        f,
        R\cdot h_N
        )
        \\
  &
  \ 
        =
  \ 
        \omega
        ( 
        f,
        R\cdot h_N
        )
        \to
        0
        \qquad
        \text{for}
        \ 
        N\to\infty
        \,,
\end{align*}
The convergence in due to $h_N\to 0$ for $N\to \infty$. 
\end{example}
We now have a large class of possible basis function. We may proceed.
