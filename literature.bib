@article{Fong2018,
  title = {Covariate Balancing Propensity Score for a Continuous Treatment: {{Application}} to the Efficacy of Political Advertisements},
  shorttitle = {Covariate Balancing Propensity Score for a Continuous Treatment},
  author = {Fong, Christian and Hazlett, Chad and Imai, Kosuke},
  year = {2018},
  month = mar,
  journal = {The Annals of Applied Statistics},
  volume = {12},
  number = {1},
  pages = {156--177},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {1932-6157, 1941-7330},
  doi = {10.1214/17-AOAS1101},
  abstract = {Propensity score matching and weighting are popular methods when estimating causal effects in observational studies. Beyond the assumption of unconfoundedness, however, these methods also require the model for the propensity score to be correctly specified. The recently proposed covariate balancing propensity score (CBPS) methodology increases the robustness to model misspecification by directly optimizing sample covariate balance between the treatment and control groups. In this paper, we extend the CBPS to a continuous treatment. We propose the covariate balancing generalized propensity score (CBGPS) methodology, which minimizes the association between covariates and the treatment. We develop both parametric and nonparametric approaches and show their superior performance over the standard maximum likelihood estimation in a simulation study. The CBGPS methodology is applied to an observational study, whose goal is to estimate the causal effects of political advertisements on campaign contributions. We also provide open-source software that implements the proposed methods.},
  keywords = {Causal inference,covariate balance,generalized propensity score,inverse-probability weighting,treatment effect},
  file = {/home/ioan/Zotero/storage/ETHSLHAR/Fong et al. - 2018 - Covariate balancing propensity score for a continu.pdf;/home/ioan/Zotero/storage/R82C7W48/17-AOAS1101.html}
}

@article{Hainmueller2012,
  title = {Entropy {{Balancing}} for {{Causal Effects}}: {{A Multivariate Reweighting Method}} to {{Produce Balanced Samples}} in {{Observational Studies}}},
  shorttitle = {Entropy {{Balancing}} for {{Causal Effects}}},
  author = {Hainmueller, Jens},
  year = {2012},
  journal = {Political Analysis},
  volume = {20},
  number = {1},
  pages = {25--46},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpr025},
  abstract = {This paper proposes entropy balancing, a data preprocessing method to achieve covariate balance in observational studies with binary treatments. Entropy balancing relies on a maximum entropy reweighting scheme that calibrates unit weights so that the reweighted treatment and control group satisfy a potentially large set of prespecified balance conditions that incorporate information about known sample moments. Entropy balancing thereby exactly adjusts inequalities in representation with respect to the first, second, and possibly higher moments of the covariate distributions. These balance improvements can reduce model dependence for the subsequent estimation of treatment effects. The method assures that balance improves on all covariate moments included in the reweighting. It also obviates the need for continual balance checking and iterative searching over propensity score models that may stochastically balance the covariate moments. We demonstrate the use of entropy balancing with Monte Carlo simulations and empirical applications.},
  langid = {english},
  file = {/home/ioan/Zotero/storage/Z5ENHQYD/Hainmueller - 2012 - Entropy Balancing for Causal Effects A Multivaria.pdf}
}

@incollection{Hirano2005,
  title = {The {{Propensity Score}} with {{Continuous Treatments}}},
  booktitle = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  author = {Hirano, Keisuke and Imbens, Guido W.},
  editor = {Gelman, Andrew and Meng, Xiao-Li},
  year = {2005},
  month = jul,
  pages = {73--84},
  publisher = {{John Wiley \& Sons, Ltd}},
  address = {{Chichester, UK}},
  doi = {10.1002/0470090456.ch7},
  isbn = {978-0-470-09045-9 978-0-470-09043-5},
  langid = {english},
  file = {/home/ioan/Zotero/storage/ARALBRYZ/Hirano and Imbens - 2005 - The Propensity Score with Continuous Treatments.pdf}
}

@article{Kang2007,
  title = {Demystifying {{Double Robustness}}: {{A Comparison}} of {{Alternative Strategies}} for {{Estimating}} a {{Population Mean}} from {{Incomplete Data}}},
  shorttitle = {Demystifying {{Double Robustness}}},
  author = {Kang, Joseph D. Y. and Schafer, Joseph L.},
  year = {2007},
  month = nov,
  journal = {Statistical Science},
  volume = {22},
  number = {4},
  pages = {523--539},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/07-STS227},
  abstract = {When outcomes are missing for reasons beyond an investigator's control, there are two different ways to adjust a parameter estimate for covariates that may be related both to the outcome and to missingness. One approach is to model the relationships between the covariates and the outcome and use those relationships to predict the missing values. Another is to model the probabilities of missingness given the covariates and incorporate them into a weighted or stratified estimate. Doubly robust (DR) procedures apply both types of model simultaneously and produce a consistent estimate of the parameter if either of the two models has been correctly specified. In this article, we show that DR estimates can be constructed in many ways. We compare the performance of various DR and non-DR estimates of a population mean in a simulated example where both models are incorrect but neither is grossly misspecified. Methods that use inverse-probabilities as weights, whether they are DR or not, are sensitive to misspecification of the propensity model when some estimated propensities are small. Many DR methods perform better than simple inverse-probability weighting. None of the DR methods we tried, however, improved upon the performance of simple regression-based prediction of the missing values. This study does not represent every missing-data problem that will arise in practice. But it does demonstrate that, in at least some settings, two wrong models are not better than one.},
  keywords = {Causal inference,missing data,model-assisted survey estimation,propensity score,weighted estimating equations},
  file = {/home/ioan/Zotero/storage/E6G6EG89/Kang and Schafer - 2007 - Demystifying Double Robustness A Comparison of Al.pdf;/home/ioan/Zotero/storage/7A9R2XDH/07-STS227.html}
}

@incollection{Mordukhovich2022,
  title = {{{ENHANCED CALCULUS AND FENCHEL DUALITY}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {255--310},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_4},
  abstract = {A large part of this chapter continues developing generalized differential calculus started in the previous chapter, but from different perspectives. Namely, we consider Fenchel conjugates and duality relationships, which are specifically related to convexity and play a fundamental role in convex analysis.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/J2CU8HGQ/Mordukhovich and Mau Nam - 2022 - ENHANCED CALCULUS AND FENCHEL DUALITY.pdf}
}

@incollection{Mordukhovich2022a,
  title = {{{MISCELLANEOUS TOPICS ON CONVEXITY}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {381--443},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_6},
  abstract = {This chapter deals with certain miscellaneous topics of convex analysis in infinite-dimensional and finite-dimensional spaces. Most of the presented developments are not directly related to generalized differentiation, although some results employ subgradients. We mainly concentrate here on strong convexity and related monotonicity of subgradient mappings, which are particularly important for Nesterov's smoothing techniques in numerical optimization; on the study of asymptotic behavior of convex sets and functions at infinity; on the considerations of the remarkable classes of signed distance and minimal time functions; and on classical finite-dimensional results related to the Carath\'eodory and Helly theorems, Farkas lemma, etc.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/2FBLTN4N/Mordukhovich and Mau Nam - 2022 - MISCELLANEOUS TOPICS ON CONVEXITY.pdf}
}

@incollection{Mordukhovich2022b,
  title = {{{FUNDAMENTALS}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {1--64},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_1},
  abstract = {This chapter collects fundamental notions and results in vector spaces, topological spaces, topological vector spaces, and their specifications that are widely used in the subsequent chapters of the book to build the basic theory of convexity and its applications.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/HR4DEAM2/Mordukhovich and Mau Nam - 2022 - FUNDAMENTALS.pdf}
}

@incollection{Mordukhovich2022c,
  title = {{{VARIATIONAL TECHNIQUES AND FURTHER SUBGRADIENT STUDY}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {311--379},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_5},
  abstract = {We start this chapter with the study of variational structures for functions and sets in complete metric and normed spaces. The major variational and extremal principles, being held even in nonconvex frameworks, are largely related to and motivated by the developments on convexity. Variational/extremal principles and variational techniques elaborated in this chapter in complete spaces are then applied to establishing density results for \$\$\textbackslash varepsilon \$\${$\epsilon$}-subgradients of convex functions and to developing \$\$\textbackslash varepsilon \$\${$\epsilon$}-subdifferential calculus with the further applications to convex mean value theorems, subdifferential monotonicity, characterizations of the Fr\'echet and G\^ateauxG\^ateaux differentiability~differentiability together with their generic properties, and finally to deriving subgradient formulas for spectral and singular functions in convex analysis. Our major results hold in Banach spaces, but some results and proofs are valid in general settings of complete metric and topological vector spaces, while those for spectral and singular functions are primarily finite-dimensional.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/248D8V7E/Mordukhovich and Mau Nam - 2022 - VARIATIONAL TECHNIQUES AND FURTHER SUBGRADIENT STU.pdf}
}

@incollection{Mordukhovich2022d,
  title = {{{CONVEX GENERALIZED DIFFERENTIATION}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {179--253},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_3},
  abstract = {Generalized differentiation lies at the very heart of convex analysis and its applications. Since the most useful and even most simple convex functions are nondifferentiable at the points of interest, the now flourishing generalized differentiation theory oriented toward optimization-related problems has started from convex analysis and then has been extended to more general variational frameworks. It concerns not only nondifferentiable functions but also sets with nonsmooth boundaries as well as set-valued mappings. Calculus rules of generalized differentiation have been the central issue of the theory and applications from the very beginning of convex analysis.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/SWYHRVJ6/Mordukhovich and Mau Nam - 2022 - CONVEX GENERALIZED DIFFERENTIATION.pdf}
}

@incollection{Mordukhovich2022e,
  title = {{{BASIC THEORY OF CONVEXITY}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {65--177},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_2},
  abstract = {This chapter is devoted to basic convexity theory dealing with sets and functions defined in various space frameworks consisting of linear/vector spaces, topological vector spaces, locally convex topological spaces and their subclasses, and also specific results in finite dimensions. Developing the geometric approach to convex analysis, we start with convex sets, establish fundamental separation theorems for them, and then proceed with the study of convex functions. Further topics on convexity, including duality and generalized differentiation theories, are considered in the subsequent chapters. Unless otherwise stated, we consider real vector spaces in this chapter and the subsequent ones.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/UF63838N/Mordukhovich and Mau Nam - 2022 - BASIC THEORY OF CONVEXITY.pdf}
}

@book{Mordukhovich2022f,
  title = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  shorttitle = {Convex {{Analysis}} and {{Beyond}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9},
  isbn = {978-3-030-94784-2 978-3-030-94785-9},
  langid = {english},
  keywords = {Convex Analysis,Convex Functions,Convex Sets,Generalized Differentiation,Locally Convex Topological Vector Spaces,Topological Vector Spaces,Variational Analysis,Variational Methods of Nonlinear Analysis},
  file = {/home/ioan/Zotero/storage/EA8EVDIW/Mordukhovich and Mau Nam - 2022 - Convex Analysis and Beyond Volume I Basic Theory.pdf}
}

@incollection{Mordukhovich2022g,
  title = {{{CONVEXIFIED LIPSCHITZIAN ANALYSIS}}},
  booktitle = {Convex {{Analysis}} and {{Beyond}}: {{Volume I}}: {{Basic Theory}}},
  author = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  editor = {Mordukhovich, Boris S. and Mau Nam, Nguyen},
  year = {2022},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  pages = {445--551},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-94785-9_7},
  abstract = {This chapter deals with nonconvex nondifferentiable functions. However, the machinery and results of convex analysis presented in the previous chapters provide crucial tools for the study of generalized differentiation beyond the function convexity. A conventional way to do it is developing a scheme using first a suitable extension of the directional derivative and then defining the corresponding directional subdifferential via a duality correspondence with such an extended directional derivative. The subgradient mappings obtained in this way are always convex-valued, but the most important properties of them are exhibited when the directional derivatives are assumed (or happen to be) convex with respect to directions. All of this constitutes the realm of convexified analysis in this chapter.},
  isbn = {978-3-030-94785-9},
  langid = {english},
  file = {/home/ioan/Zotero/storage/V6ZZGDI4/Mordukhovich and Mau Nam - 2022 - CONVEXIFIED LIPSCHITZIAN ANALYSIS.pdf}
}

@article{Rosenbaum1983,
  title = {The {{Central Role}} of the {{Propensity Score}} in {{Observational Studies}} for {{Causal Effects}}},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  year = {1983},
  journal = {Biometrika},
  volume = {70},
  number = {1},
  pages = {41--55},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  issn = {0006-3444},
  doi = {10.2307/2335942},
  abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two-dimensional plot.},
  file = {/home/ioan/Zotero/storage/4CHPRN4I/Rosenbaum and Rubin - 1983 - The Central Role of the Propensity Score in Observ.pdf;/home/ioan/Zotero/storage/H6FYUCVL/rosenbaum_1983.pdf}
}

@misc{Tropp2015,
  title = {An {{Introduction}} to {{Matrix Concentration Inequalities}}},
  author = {Tropp, Joel A.},
  year = {2015},
  month = jan,
  number = {arXiv:1501.01571},
  eprint = {1501.01571},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  abstract = {In recent years, random matrices have come to play a major role in computational mathematics, but most of the classical areas of random matrix theory remain the province of experts. Over the last decade, with the advent of matrix concentration inequalities, research has advanced to the point where we can conquer many (formerly) challenging problems with a page or two of arithmetic. The aim of this monograph is to describe the most successful methods from this area along with some interesting examples that these techniques can illuminate.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Information Theory,Mathematics - Numerical Analysis,Mathematics - Probability,Primary: 60B20. Secondary: 60F10; 60G50; 60G42,Statistics - Machine Learning},
  file = {/home/ioan/Zotero/storage/WRB3MWEN/Tropp - 2015 - An Introduction to Matrix Concentration Inequaliti.pdf}
}

@article{Wang2019,
  title = {Minimal {{Dispersion Approximately Balancing Weights}}: {{Asymptotic Properties}} and {{Practical Considerations}}},
  shorttitle = {Minimal {{Dispersion Approximately Balancing Weights}}},
  author = {Wang, Yixin and Zubizarreta, Jos{\'e} R.},
  year = {2019},
  month = oct,
  journal = {Biometrika},
  eprint = {1705.00998},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  pages = {asz050},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asz050},
  abstract = {Weighting methods are widely used to adjust for covariates in observational studies, sample surveys, and regression settings. In this paper, we study a class of recently proposed weighting methods which find the weights of minimum dispersion that approximately balance the covariates. We call these weights "minimal weights" and study them under a common optimization framework. The key observation is the connection between approximate covariate balance and shrinkage estimation of the propensity score. This connection leads to both theoretical and practical developments. From a theoretical standpoint, we characterize the asymptotic properties of minimal weights and show that, under standard smoothness conditions on the propensity score function, minimal weights are consistent estimates of the true inverse probability weights. Also, we show that the resulting weighting estimator is consistent, asymptotically normal, and semiparametrically efficient. From a practical standpoint, we present a finite sample oracle inequality that bounds the loss incurred by balancing more functions of the covariates than strictly needed. This inequality shows that minimal weights implicitly bound the number of active covariate balance constraints. We finally provide a tuning algorithm for choosing the degree of approximate balance in minimal weights. We conclude the paper with four empirical studies that suggest approximate balance is preferable to exact balance, especially when there is limited overlap in covariate distributions. In these studies, we show that the root mean squared error of the weighting estimator can be reduced by as much as a half with approximate balance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Applications,Statistics - Methodology},
  file = {/home/ioan/Zotero/storage/Z95A68CS/Wang and Zubizarreta - 2019 - Minimal Dispersion Approximately Balancing Weights.pdf}
}

@article{Wang2023,
  title = {Large {{Sample Properties}} of {{Matching}} for {{Balance}}},
  author = {Wang, Yixin and Zubizarreta, Jos{\'e} R.},
  year = {2023},
  journal = {Statistica Sinica},
  eprint = {1905.11386},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  issn = {10170405},
  doi = {10.5705/ss.202020.0343},
  abstract = {Matching methods are widely used for causal inference in observational studies. Among them, nearest neighbor matching is arguably the most popular. However, nearest neighbor matching does not generally yield an average treatment effect estimator that is \$\textbackslash sqrt\{n\}\$-consistent (Abadie and Imbens, 2006). Are matching methods not \$\textbackslash sqrt\{n\}\$-consistent in general? In this paper, we study a recent class of matching methods that use integer programming to directly target aggregate covariate balance as opposed to finding close neighbor matches. We show that under suitable conditions these methods can yield simple estimators that are \$\textbackslash sqrt\{n\}\$-consistent and asymptotically optimal.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  file = {/home/ioan/Zotero/storage/NBRATHRB/Wang and Zubizarreta - 2023 - Large Sample Properties of Matching for Balance.pdf}
}

@article{Zubizarreta2015,
  title = {Stable {{Weights}} That {{Balance Covariates}} for {{Estimation With Incomplete Outcome Data}}},
  author = {Zubizarreta, Jos{\'e} R.},
  year = {2015},
  month = jul,
  journal = {Journal of the American Statistical Association},
  volume = {110},
  number = {511},
  pages = {910--922},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2015.1023805},
  abstract = {Weighting methods that adjust for observed covariates, such as inverse probability weighting, are widely used for causal inference and estimation with incomplete outcome data. Part of the appeal of such methods is that one set of weights can be used to estimate a range of treatment effects based on different outcomes, or a variety of population means for several variables. However, this appeal can be diminished in practice by the instability of the estimated weights and by the difficulty of adequately adjusting for observed covariates in some settings. To address these limitations, this paper presents a new weighting method that finds the weights of minimum variance that adjust or balance the empirical distribution of the observed covariates up to levels prespecified by the researcher. This method allows the researcher to balance very precisely the means of the observed covariates and other features of their marginal and joint distributions, such as variances and correlations and also, for example, the quantiles of interactions of pairs and triples of observed covariates, thus balancing entire two- and three-way marginals. Since the weighting method is based on a well-defined convex optimization problem, duality theory provides insight into the behavior of the variance of the optimal weights in relation to the level of covariate balance adjustment, answering the question, how much does tightening a balance constraint increases the variance of the weights? Also, the weighting method runs in polynomial time so relatively large data sets can be handled quickly. An implementation of the method is provided in the new package sbw for R. This paper shows some theoretical properties of the resulting weights and illustrates their use by analyzing both a data set from the 2010 Chilean earthquake and a simulated example.},
  langid = {english},
  file = {/home/ioan/Zotero/storage/EI2GZH6U/Zubizarreta - 2015 - Stable Weights that Balance Covariates for Estimat.pdf}
}

